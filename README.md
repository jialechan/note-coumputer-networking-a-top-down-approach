# 计算机网络和因特网
## 1.1 什么是因特网
回答这个问题有两种方式：其一，我们能够描述因特网的**具体构成**，即构成因特网的基本硬件和软件组件；其二，我们能够根据为分布式应用提供服务的联网**基础设施**来描述因特网。
### 1.1.1 具体构成描述
因特网中的设备可以称为**主机**（host）或**端系统**（endsystem）。端系统通过**通信链路**（communication link）（同轴电缆、铜线、光纤和无线电频谱）和**分组交换机**（packet switch）连接到一起。设备间把数据将**分段**发送，称为**分组**（pakcet），目的端系统将分组装配为初始数据。最常见的分组交换机类型是**路由器**(router)（通常用于网络核心）和**链路层交换机**(link-layer switch)（通常用于接入网）。   
端系统通过**因特网服务提供商**（Internet Service Provider, ISP）接入因特网，包括如本地电缆或电话公司那样的住宅区ISP、公司ISP、大学ISP。   
端系统、分组交换机和其他因特网部件都要运行一系列**协议**（protocol）,这些协议控制因特网中信息的接收和发送。**TCP**（Transmission Control Protocol,传输控制协议）和**IP**（Internet Protocol,网际协议）是因特网中两个最为重要的协议。
**因特网工程任务组**(Internet Engineering Task Force, IETF)主要工作是定义**请求评论**(Request For Comment, RFC)，RFC定义了TCP、IP、HTTP(用于Web)和SMTP (用于电子邮件)等协议。   
<img src="https://github.com/user-attachments/assets/b26bee42-dcf3-4423-8b23-c397964c2ab3" width="400px"/>
### 1.1.2 服务描述
因特网为分布式应用程序提供了基础设施服务：**套接字接口**( socket interface)，该接口规定了运行在一个端系统上的程序请求因特网基础设施向运行在另一个端系统上的特定目的地程序交付数据的方式。
### 1.1.3 什么是协议
**协议**(protocol)定义了在两个或多个通信实体之间交换的报文的格式和顺序，以及报文发送和/或接收一条报文或其他事件所采取的动作。掌握计算机网络领域知识的过程就是理解网络协议的构成、原理和工作方式
的过程。
## 1.2 网路边缘
### 1.2.1 接入网
**接入网**这是指将端系统物理连接到其**边缘路由器**（edge router）的网络。边缘路由器是端系统到任何其他远程端系统的路径上的第一台路由器。   
   
1.家庭接入：DSL 电缆、FTTH 拨号和卫星   
**数字用户线**（Digital Subscriber Line, DSL），住户通常从提供本地电话接入的本地电话公司处获得DSL因特网接入。   
<img src="https://github.com/user-attachments/assets/4159cfe4-d727-430e-8f02-2a2763037050" width="500px"/>   

**电缆因特网接入**（cable Internet access）利用了有线电视公司现有的有线电视基础设施。因为在这个系统中应用了光纤和同轴电缆，所以它经常被称为混合光纤同轴（Hybrid Fiber Coax, HFC）系统。   
<img width="500" alt="image" src="https://github.com/user-attachments/assets/736a5dad-b3f9-4597-b457-ebc295e09d95">   

**光纤到户**(Fiber To The Home, FTTH) 从本地中心局直接到家庭提供了一条光纤路径。直接光纤，从本地中心局到每户设置一根光纤。

从中心局岀来的每根光纤实际上由许多家庭共享，直到相对接近这些家庭的位置，该光纤才分成每户一根光纤：**主动光纤网络**（Active Optical Network, AON)和**被动光纤网络**(Passive Optical Network, PON)   
<img width="500" alt="image" src="https://github.com/user-attachments/assets/005c133b-1d4a-465c-af48-ac327692c8b4">    

**拨号**速度慢，使用的是电话线；**卫星链路**提供1Mbps以上网速。   

2.企业（和家庭）接入：以太网和WiFi
在公司和大学校园以及越来越多的家庭环境中，使用**局域网**(LAN)将端系统连接到边缘路由器。**以太网**是目前最流行的局域网接入技术。   
<img width="500" alt="image" src="https://github.com/user-attachments/assets/9b8680ef-7954-4a11-b5ae-eb839bb0aa41">    

今天许多家庭将宽带住宅接入（即电缆调制解调器或DSL）与廉价的无线局域网技术结合起来，以产生强大的家用网络。  

3.广域无线接入：3G和LTE
3G提供超过1Mbps的速率。LTE (Long-Term Evolution)来源于3G技术，它能够取得超过10Mbps的速率。

### 1.2.2 物理媒体
1. **双绞铜线**：最便宜并且最常用的导引型传输媒体，一直用于电话网。6a类电缆能够达到10Gbps的数据传输速率，距离长达100m。
2. **同轴电缆**：常建议电缆电视系统。为住宅用户提供数十Mbps速率的因特网接入。同轴电缆能被用作导引型共享媒体(shared medium)，产生的模拟信号从发送设备传送到一个或多个接收方。特别是，许多端系统能够直接与该电缆相连，每个端系统都能接收由其他端系统发送的内容。
3. **光纤**：比特速率高达数十甚至数百Gbps。抗干扰，传输距离100km，难窃听。
4. **陆地无线电信道**：一类运行在很短距离（如1米或2米）；另一类运行在局域，通常跨越数十到几百米；第三类运行在广域，跨越数万米。
5. **卫星无线电信道**：同步卫星有280ms信号传播时延；数百Mbps速率。

## 1.3 网络核心
通过网络链路和交换机移动数据有两种基本方法：分组交换（packet switching）和电路交换（circuit switching）。
### 1.3.1 分组交换
1. **存储转发传输**：在交换机能够开始向输岀链路传输该分组的第一个比特之前，必须接收到整个分组。
2. **排队时延和分组丢失**：对于每条相连的链路，该分组交换机具有一个输出缓存（output buffer,也称为输出队列（output queue））。因此，除了存储转发时延以外，分组还要承受输岀缓存的**排队时延**（queuing delay）。因为缓存空间的大小是有限的，一个到达的分组可能发现该缓存已被其他等待传输的分组完全充满了。在此情况下，将出现分组**丢失（丢包）**（packet loss），到达的分组或已经排队的分组之一将被丢弃。
3. **转发表和路由选择协议**：每台路由器具有一个**转发表**(forwarding table)，用于将目的地址(或目的地址的一部分)映射成为输岀链路。你因特网具有一些特殊的**路由选择协议**（routing protocol）,用于自动地设置路由的转发表。

<img width="500" alt="image" src="https://github.com/user-attachments/assets/e700f3b6-5651-403e-9659-ed900e56842a"> 

### 1.3.2 电路交换
电路使用的是**端到端连接**（end to-end connection），在端系统间通信会话期间，**预留**了端系统间沿路径通信所需要的资源（缓存，链路传输速率）。链路中的电路是通过**频分复用** (Frequency- Division Multiplexing, FDM )或**时分复用**（Time-Division Multiplexing, TDM）来实现的。

<img width="500" alt="image" src="https://github.com/user-attachments/assets/0467a69d-5e69-4835-bfd9-103749b7b0d5">    

**分组交换与电路交换的对比**：分组交换提供更好的带宽共享、更简单，更高效，成本更低；电路交换更适合实时服务(电话和视频会议)，但代价可能有点高。目前趋势向分组交换转。

### 1.3.3 网络的网络
今天的因特网是一个网络的网络，其结构复杂，由十多个第一层ISP和数十万个较低层ISP组成。ISP覆盖的区域多种多样，有些跨越多个大洲和大洋，有些限于狭窄的地理区域。较低层的ISP与较高层的ISP相连，较高层ISP彼此互联。用户和内容
提供商是较低层ISP的客户，较低层ISP是较高层ISP的客户。近年来，主要的内容提供商也已经创建自己的网络，直接在可能的地方与较低层ISP互联。   

<img width="500" alt="image" src="https://github.com/user-attachments/assets/970fde9a-7c53-4d92-a508-17e91a655dc0">    

## 1.4 分组交换网络中的时延、丢包和吞吐量
### 1.4.1 分组交换网中的时延概述
1. **处理时延**
检查分组首部和决定将该分组导向何处所需要的时间是**处理时延**的一部分。高速路由器的处理时延通常是**微秒**或更低的数量级。在这种节点处理之后，路由器将该分组引向通往路由器B链路之前的队列。
2. **排队时延**
在队列中，当分组在链路上等待传输时，它经受排队时延。实际的排队时延可以是**毫秒到微秒量**级。
3. **传输时延**
将所有分组的比特推向链路(即传输，或者说发射)所需要的时间。分组长度除以链路带宽。实际的传输时延通常在**毫秒到微秒量**级。
4. **传播时延**
等于或略小于光速。在广域网中，传播时延为**毫秒**量级。

**传输时延和传播时延的比较**: 传输时延是路由器推出分组所需要的时间，它是**分组长度**和**链路传输速率**的函数，而与两台路由器之间的**距离**无关。另一方面，传播时延是一个比特从一台路由器传播到另一台路由器所需要的时间，它是两台路由器之间**距离**的函数，而与**分组长度**或**链路传输速率**无关。

### 1.4.2 排队时延和丢包
随着流量强度接近于1,平均排队时延迅速增加。该强度的少量增加将导致时延大比例增加。   
![image](https://github.com/user-attachments/assets/60d8103d-6c51-487c-9e21-36fb5b2a7dbf)   

**丢包**：当到达分组发现一个满的队列，由于没有地方存储这个分组，路由器将丢弃(drop)该分组。丢失的分组可能基于端到端的原则重传，以确保所有的数据最终从源传送到了目的地。

### 1.4.3 端到端时延
1. Traceroute：观察链路中源到各个路由的时延。
2. 端系统、应用程序和其他时延：
      * 共享媒体（例如在WiFi或电缆调制解调器情况下）传输分组的端系统可能有意地延迟它的传输，把这作为它与其他端系统共享媒体的协议的一部分；
      * 是媒体分组化时延，这种时延出现在IP语音 VoIP）应用中。在VoIP中，发送方在向因特网传递分组之前必须首先用编码的数字化语音填充一个分组。

### 1.4.4 计算机网络的吞吐量
如果没有共享链路，那么吞吐量约等于最小链路的传输速率；有共享带宽的情况，取决于共享链路的实际实时情况（受网络繁忙情况影响）。

## 1.5 协议层次及服务模型
### 1.5.1 分层的体系结构
![image](https://github.com/user-attachments/assets/d29f858d-7001-4c1d-955b-aaf7c97f31aa)   

**因特网协议栈**   
1. **应用层**：应用层是网络应用程序及它们的应用层协议存留的地方。因特网的应用层包括许多协议，例如HTTP （它提供了 Web文档的请求和传送）、SMTP （它提供了电子邮件报文的传输）和FTP （它提供两个端系统之间的文件传
送）、DNS（域名解析）。应用层协议分布在多个端系统上，而一个端系统中的应用程序使用协议与另一个端系统中的应用程序交换信息分组。我们把这种位于应用层的信息分组称为**报文**(message）
2. **运输层**：因特网的运输层在应用程序端点之间传送应用层报文。在因特网中，有两种运输协议，即**TCP**和**UDP**,利用其中的任一个都能运输应用层报文。TCP向它的应用程序提供了面向连接的服务。这种服务包括了应用层报文向目的地的**确保传**递和**流量控制**（即发送方/接收方速率匹配）。TCP也将长报文划分为短报文，并提供**拥塞控制**机制，因此当网络拥塞时，源抑制其传输速率。UDP协议向它的应用程序提供无连接服务。这是一种不提供不必要服务的服务，没有可靠性，没有流量控制，也没有拥塞控制。运输层的分组称为**报文段** (segment)。
3. **网络层**：因特网的网络层负责将称为**数据报**（datagram）的网络层分组从一台主机移动到另一台主机。在一台源主机中的因特网运输层协议（TCP或UDP）向网络层递交运输层报文段和目的地址，就像你通过邮政服务寄信件时提供一个目的地址一样。因特网的网络层包括著名的**网际协议IP**,该协议定义了在数据报中的各个字段以及端系统和路由器如何作用于这些字段。IP仅有一个，所有具有网络层的因特网组件必须运行IP。因特网的网络层也包括决定路由的路由选择协议，它根据该路由将数据报从源传输到目的地。尽管网络层包括了网际协议和一些**路由选择**协议，但通常把它简单地称为IP层，这反映了IP是将因特网连接在一起的黏合剂这样的事实。
4. **链路层**：由链路层提供的服务取决于该链路的特定链路层协议。例如，某些协议基于链路提供可靠传递，从传输节点跨越一条链路到接收节点。值得注意的是，这种可靠的传递服务不同于TCP的可靠传递服务，TCP提供从一个端系统到另一个端系统的可靠交付。链路层的例子包括以太网、WiFi和电缆接入网的**DOCSIS**协议。因为数据报从源到目的地传送通常需要经过几条链路，一个数据报可能被沿途不同链路上的不同链路层协议处理。例如，一个数据报可能被一段链路上的以太网和下一段链路上的**PPP**所处理。网络层将受到来自每个不同的链路层协议的不同服务。把链路层分组称为**帧**(frame）
5. **物理层**：将帧中的一个个比特从一个节点移动到下一个节点。在这层中的协议仍然是链路相关的，并且进一步与该链路（例如，双绞铜线、单模光纤）的实际传输媒体相关。例如，以太网具有许多物理层协议：一个是关于双绞铜线的，另一个是关于同轴电缆的，还有一个是关于光纤的，等等。在每种场合中，跨越这些链路移动一个比特是以不同的方式进行的。

**OSI模型**   
因特网协议栈不是唯一的协议栈，开放系统互联(OSI)由ISO在70年代提出在先，比因特网协议还早。 

OSI参考模型比因特网协议多了两个层，即**表示层**和**会话层**。   
**表示层**的作用是使通信的应用程序能够解释交换数据的含义。这些服务包括数据压缩和数据加密（它们是自解释的）以及数据描述（这使得应用程序不必担心在各台计算机中表示/存储的内部格式不同的问题）。   
**会话层**提供了数据交换的定界和同步功能，包括了建立检查点和恢复方案的方法。   

因特网缺少这两个层，因为因特网把这两个层的功能实现留给了应用层的开发者自行决定。

### 1.5.2 封装
<img width="700" alt="image" src="https://github.com/user-attachments/assets/c3532a40-b88d-43a4-add5-57fa9de0b35f">   

## 1.6 面对网络攻击
1. 坏家伙能够经因特网将有害程序放入你的计算机中
**僵尸网络**（botnet）大量被控制的主机；**病毒**(virus）是一种需要某种形式的用户交互来感染用户设备的恶意软件。**蠕虫**(worm）是一种无须任何明显用户交互就能进入设备的恶意软件。例如,用户也许运行了一个攻击者能够发送恶意软件的脆弱网络应用程序。
2. 坏家伙能够攻击服务器和网络基础设施   
**拒绝服务攻击**（Denial-of Service(DoS)attack）
   * **弱点攻击**。这涉及向一台目标主机上运行的易受攻击的应用程序或操作系统发送制作精细的报文。该服务器可能停止运行，或者更糟糕的是主机可能崩溃。
   * **带宽洪泛**。攻击者向目标主机发送大量的分组，分组数量之多使得目标的接入链路变得拥塞，使得合法的分组无法到达服务器。
   * **连接洪泛**。攻击者在目标主机中创建大量的半开或全开TCP连接。该主机因这些伪造的连接而陷入困境，并停止接受合法的连接
3. 坏家伙能够嗅探分组
在无线环境，有线广播环境中，比如以太网LAN中，电缆接入技术中，被控制的路由器中，被动的**分组嗅探器**(packet sniffer)能获得分组的副本。防御嗅探器的方法基本都与密码学有关。   
4. 坏家伙能够伪装成你信任的人
将具有虚假源地址的分组注入因特网的能力被称为**IP哄骗**（IP spoofing）,而它只是一个用户能够冒充另一个用户的许多方式中的一种。为了解决这个问题，我们需要采用端点鉴别，即一种使我们能够确信一个报文源自我们认为它应当来自的地方的机制。

## 1.7 计算机网络和因特网的历史
### 1.7.1 分组交换的发展: 1961~1972
### 1.7.2 专用网络和网络互联: 1972~1980
### 1.7.3 网络的激增: 1980~1990
### 1.7.4 因特网爆炸: 20世纪90年代
### 1.7.5 最新发展
* 自2000年开始，我们见证了家庭宽带因特网接入的积极部署
* 高速(54Mbps及更高)公共WiFi网络和经过4G蜂窝电话网的中速(几十Mbps)因特网接入越来越普及
* 社交网络大发展
* 在线服务提供商如谷歌和微软已经广泛部署了自己的专用网络。
* 许多因特网商务公司在“云”（如亚马逊的EC2 谷歌的应用引擎、微软的Azure）中运行它们的应用。

## 1.8小结
我们已经看到构成特别的因特网以及一般的计算机网络的各种硬件和软件。我们从网络的边缘开始，观察端系统和应用程序，以及运行在端系统上为应用程序提供的运输服务。接着我们也观察了通常能够在接入网中找到的链路层技术和物理媒体。然后我们进入网络核心更深入地钻研网络，看到分组交换和电路交换是通过电信网络传输数据的两种基本方法，并且探讨了每种方法的长处和短处。我们也研究了全球性因特网的结构，知道了因特网是网络的网络。我们看到了因特网的由较高层和较低层ISP组成的等级结构，允许该网络扩展为包括数以千计的网络。   

在这个概述性章节的第二部分，我们研究了计算机网络领域的几个重要主题。我们首先研究了分组交换网中的时延、吞吐量和丢包的原因。我们研究得到传输、传播和排队时延以及用于吞吐量的简单定量模型；我们将在整本书的课后习题中多处使用这些时延模型。接下来，我们研究了协议分层和服务模型、网络中的关键体系结构原则，我们将在本书多处引用它们。我们还概述了在今天的因特网中某些更为流行的安全攻击。我们用计算机网络的简要历史结束我们对网络的概述。

# 应用层
## 2.1 应用层协议原理
### 2.1.1 网络应用程序体系结构
* **客户-服务器体系结构**（client-server architecture）：有一个总是打开的主机称为服务器，它服务于来自许多其他称为客户的主机的请求。
* **P2P体系结构**（P2P architecture）：对位于数据中心的专用服务器有最小的（或者没有）依赖。相反，应用程序在间断连接的主机对之间使用直接通信，这些主机对被称为**对等方**。P2P体系结构特性之一是它们的**自扩展性**（self-scalability），由于高度非集中式结构，P2P面临安全性、性能和可靠性等挑战。

### 2.1.2 进程通讯
1. 客户和服务器进程：在一对进程之间的通信会话场景中，发起通信（即在该会话开始时发起与其他进程的联系）的进程被标识为客户，在会话开始时等待联系的进程是服务器。
2. 进程与计算机网络之间的接口：进程通过一个称为套接字(socket)的软件接口向网络发送报文和从网络接收报文。套接字是同一台主机内应用层与运输层之间的接口。由于该套接字是建立网络应用程序的可编程接口，因此套接字也称为应用程序和网络之间的**应用程序编程接口**(Application Programming Interface, API)。应用程序开发者可以控制套接字在应用层端的一切，但是对该套接字的运输层端几乎**没有**控制权。应用程序开发者对于运输层的控制仅限于：①选择运输层协议；②也许能设定几个运输层参数，如最大缓存和最大报文段长度等。
3. 进程寻址：①主机的地址，由**IP地址**标识。②在目的主机中指定接收进程的标识符，由目的地**端口号**标识。

### 2.1.3 可供应用程序使用的运输服务
1. **可靠数据传输**：确保由应用程序的一端发送的数据正确、完全地交付给该应用程序的另一端。如果一个协议提供了这样的确保数据交付服务，就认为提供了**可靠数据传输**(reliable dtatransfer)。
2. **吞吐量**：即运输层协议能够以某种特定的速率提供确保的可用吞吐量。
3. **定时**：即运输层协议也能提供定时保证。例如发送方注入进套接字中的每个比特到达接收方的套接字不迟于100ms。
4. **安全性**：即运输协议能够为应用程序提供一种或多种安全性服务。运输协议能以防该数据以某种方式在这两个进程之间被观察到。运输协议还能提供除了机密性以外的其他安全性服务，包括数据完整性和端点鉴别

### 2.1.4 因特网提供的运输服务
![image](https://github.com/user-attachments/assets/ecbf9d59-88db-48ca-9833-5a07fcfb2a8f)
1. TCP服务
   * 面向连接的服务：在应用层数据报文开始流动之前，TCP让客户和服务器互相交换运输层控制信息。这个所谓的握手过程提醒客户和服务器，让它们为大量分组的到来做好准备。在握手阶段后，一个TCP连接（TCP connection）就在两个进程的套接字之间建立了。这条连接是全双工的，即连接双方的进程可以在此连接上同时进行报文收发。当应用程序结束报文发送时，必须拆除该连接。
   * 可靠的数据传送服务：通信进程能够依靠TCP,无差错、按适当顺序交付所有发送的数据。当应用程序的一端将字节流传进套接字时，它能够依靠TCP将相同的字节流交付给接收方的套接字，而没有字节的丢失和冗余。
2. UDP服务
   * UDP协议提供一种不可靠数据传送服务。进程将一个报文发送进UDP套接字时，UDP协议并不保证该报文将到达接收进程。不仅如此，到达接收进程的报文也可能是乱序到达的。UDP没有包括拥塞控制机制，所以UDP的发送端可以用它选定的任何速率向其下层（网络层）注入数据。（然而，值得注意的是实际端到端吞吐量可能小于该速率，这可能是因为中间链路的带宽受限或因为拥塞而造成的。）

![image](https://github.com/user-attachments/assets/614a8955-567c-4cf7-975d-62d39e059cd3)   

**因特网运输协议所不提供的服务**：因特网能够提供可靠数据传输、安全性。因特网通常能够为时间敏感应用提供满意的服务，但它不能提供任何定时或带宽保证。

### 2.1.5 应用层协议
应用层协议定义了 ：
* 交换的报文类型，例如请求报文和响应报文。
* 各种报文类型的语法，如报文中的各个字段及这些字段是如何描述的。
* 字段的语义，即这些字段中的信息的含义。
* 确定一个进程何时以及如何发送报文，对报文进行响应的规则

### 2.1.6 本书涉及的网络应用
Web 文件传输、电子邮件、目录服务(DNS)、流式视频和P2P。

## 2.2 Web 和 HTTP
### 2.2.1 HTTP 概况
HTTP使用TCP作为它的支撑运输协议，HTTP是一个无状态协议(stateless protocol)。

### 2.2.2 非持续连接和持续连接
1. 采用非持续连接的HTTP：每次请求完都会断开
2. 采用持续连接的HTTP：会复用链接

### 2.2.3 HTTP报文格式
1. HTTP请求报文
<img width="300" alt="image" src="https://github.com/user-attachments/assets/aa69bae3-9e3e-46d7-9567-ae8a05f7a050">   
<br/>
<img width="400" alt="image" src="https://github.com/user-attachments/assets/43df06e0-141e-409a-9d85-f25eba6ed7e5">       

2. HTTP响应报文
<img width="300" alt="image" src="https://github.com/user-attachments/assets/e1e84302-044c-4e74-80a3-f71798f94b3c">   
<br/>
<img width="400" alt="image" src="https://github.com/user-attachments/assets/55b33fe7-1232-4df6-9d3a-240d241dbe6a">    

### 2.2.4用户与服务器的交互：cookie
cookie技术有4个组件：
1. 在HTTP响应报文中的一个cookie首部行；
2. 在HTTP请求报文中的一个cookie首部行；
3. 在用户端系统中保留有一个cookie文件，并由用户的浏览器进行管理；
4. 位于Web站点的一个后端数据库。

<img width="500" alt="image" src="https://github.com/user-attachments/assets/b6aa5622-5e81-4256-a310-a95a5ff524a1">  

### 2.2.5 Web缓存
局域网内的web缓存器：在局域网安装，局域网内的浏览器要预先设置指向局域网web缓存器（这样的话感觉用得比较少）。   

<img width="300" alt="image" src="https://github.com/user-attachments/assets/ad256475-aceb-42af-a15c-09400dde0f87">  

装在Internet公网的web缓存器：通过使用**内容分发网络**（Content Distribution Network, CDN） , Web缓存器正在因特网中发挥着越来越重要的作用。

### 2.2.6 条件GET方法
首先，一个代理缓存器（proxycache）代表一个请求浏览器，向某Web服务器发送一个请求报文
```http
GET /fruit/kiwi.gif HTTP/1.1
Host: www.exotiquecuisine.com
```
其次，该Web服务器向缓存器发送具有被请求的对象的响应报文:
```http
HTTP/1.1 200 OK
Date: Sat. 3 Oct 2015 15:39:29
Server: Apache/1.3.0 (Unix)
Last-Modified: Wed, 9 Sep 2015 09:23:24
Content-Type: image/gif
(data data data data data...)
```
下次访问Web服务器，带一个首部行，key为If-modified-since，值为上次返回的Last-Modified返回的值
```http
GET /fruit/kiwi.gif HTTP/1.1
Host: www.exotiquecuisine.com
If-modified-since: Wed, 9 Sep 2015 09:23:24
```
Web服务发现没有改变，返回304和空的body
```http
HTTP/1.1 304 Not Modified
Date: Satf 10 Oct 2015 15:39:29
Server: Apache/1 3 0 (Unix)
(empty entity body)
```

## 2.3 因特网中的电子邮件
<img width="500" alt="image" src="https://github.com/user-attachments/assets/d280b4f7-f238-4371-94a4-31c6025aac90">

### 2.3.1 SMTP
1. Alice调用她的邮件代理程序并提供Bob的邮件地址（例如bob® someschool.edu）,撰写报文，然后指示用户代理发送该报文。
2. Alice的用户代理把报文发给她的邮件服务器，在那里该报文被放在报文队列中。
3. 运行在Alice的邮件服务器上的SMTP客户端发现了报文队列中的这个报文，它就创建一个到运行在Bob的邮件服务器上的SMTP服务器的TCP连接。
4. 在经过一些初始SMTP握手后，SMTP客户通过该TCP连接发送Alice的报文。
5. 在Bob的邮件服务器上，SMTP的服务器端接收该报文。Bob的邮件服务器然后将该报文放入Bob的邮箱中。
6. 在Bob方便的时候，他调用用户代理阅读该报文。
![image](https://github.com/user-attachments/assets/2adad483-b5d1-424d-8ada-e35fa9c0567b)    

![image](https://github.com/user-attachments/assets/c97af875-92f5-4545-a83e-eee520fe63bc)   

**特别地：SMTP 一般不使用中间邮件服务器发送邮件，即使这两个邮件服务器位于地球的两端也是这样**。

### 2.3.2 SMTP与HTTP的对比
1. HTTP主要是一个**拉协议**(pull protocol), SMTP基本上是一个**推协议**(push protocol）。
2. SMTP要求每个报文（包括它们的体）采用7比特ASCII码格式。如果某报文包含了非7比特ASCII字符（如具有重音的法文字符）或二进制数据（如图形文件），则该报文必须按照7比特ASCII码进行编码。HTTP数据则不受这种限制
3. 重要区别是如何处理一个既包含文本又包含图形（也可能是其他媒体类型）的文档。HTTP把每个对象封装到它自己的HTTP响应报文中，而SMTP则把所有报文对象放在一个报文之中。

### 2.3.3 邮件报文格式
注意到下列事实：这些首部行不同于我们在2.3.1节所学到的SMTP命令（即使那里包含了某些相同的词汇,如from和to） 那节中的命令是SMTP握手协议的一部分；本节中考察的首部行则是邮件报文自身的一部分。   
一个经典的报文首部看起来如下：   
```smtp
From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life.
```

### 2.3.4 邮件访问协议
![image](https://github.com/user-attachments/assets/8c72b5ac-fdca-4611-9787-98ac5de9b3c6)

1. POP3：一个极为简单的邮件访问协议
2. IMAP：可以管理邮件和文件夹关系等比较复杂的协议
3. 基于Web的电子邮件：有浏览器作为用户代理

## 2.4 DNS: 因特网的目录服务
### 2.4.1 DNS提供的服务
DNS是：   
1. 一个由分层的DNS服务器（DNS server）实现的分布式数据库；
2. 一个使得主机能够查询分布式数据库的应用层协议。

DNS还提供了一些重要的服务：
* **主机别名**（host aliasing）：有着复杂主机名的主机能拥有一个或者多个别名。
* **邮件服务器别名**（mail server aliasing）：MX记录允许一个公司的邮件服务器和Web服务器使用相同（别名化的）的主机名；
* **负载分配**（load distribution）：因为客户通常总是向IP地址排在最前面的服务器发送HTTP请求报文，所以DNS就在所有这些冗余的Web服务器之间循环分配了负载。

### 2.4.2 DNS工作机理概述
1. 分布式、层次数据库
![image](https://github.com/user-attachments/assets/2a1c2f4f-89ec-400c-a109-f401b34dc084)
* 根DNS服务器
* 顶级域(DNS)服务器
* 权威DNS服务器


![image](https://github.com/user-attachments/assets/a274ca62-21a3-4ee7-9a06-8a22ef57f7d8)

2. DNS缓存
DNS服务可以缓存域名解析到本地存储器而不必每次都要请求查询。缓存通常2天过期时间。

### 2.4.3 DNS记录和报文
了资源记录(Resource Record, RR), RR提供了主机名到IP地址的映射。资源记录是一个包含了下列字段的4元组:
```
(Name, Value, Type, TTL)
```
Name和Value的值取决于Type:    
* 如果Type = A,则Name是主机名，Value是该主机名对应的IP地址。因此，一条类型为A的资源记录提供了标准的主机名到IP地址的映射。例如(relay1.bar.foo.com, 145. 37.93. 126, A)就是一条类型 A 记录。
* 如果Type = NS,则Name是个域(如foo. com),而Value是个知道如何获得该域中主机IP地址的权威DNS服务器的主机名。这个记录用于沿着查询链来路由DNS查询。例如(foo.com, dns.foo.com, NS)就是一条类型为NS的记录。
* 如果Type = CNAME，则Value是别名为Name的主机对应的规范主机名。该记录能够向査询的主机提供一个主机名对应的规范主机名，例如(foo.com, relay1.bar.foo.com, CNAME)就是一条 CNAME 类型的记录。
* 如果Type = MX,则Value是个别名为Name的邮件服务器的规范主机名。举例来说，(foo.com, mail.bar.foo.com, MX)就是一条MX记录。MX记录允许邮件服务器主机名具有简单的别名。值得注意的是，通过使用MX记录，一个公司的邮件服务器和其他服务器(如它的Web服务器)可以使用相同的别名。为了获得邮件服务器的规范主机名，DNS客户应当请求一条MX记录；而为了获得其他服务器的规范主机名，DNS客户应当请求CNAME记录。

如果一台DNS服务器是用于某特定主机名的权威DNS服务器，那么该DNS服务器会有一条包含用于该主机名的类型A记录(即使该DNS服务器不是其权威DNS服务器，它也可能在缓存中包含有一条类型A记录)。   

如果服务器不是用于某主机名的权威服务器,那么该服务器将包含一条类型NS记录，该记录对应于包含主机名的域；它还将包括一条类型A记录，该记录提供了在NS记录的Value字段中的DNS服务器的IP地址。举例来说，假设一台edu TLD服务器不是主机gaia.cs.umass.edu的权威DNS服务器，则该服务器将包含一条包括主机cs.umass.edu的域记录，如 (umass.edu, dns.umass.edu, NS)该edu TLD服务器还将包含一条类型A记录,如(dns.umass.edu, 128.119.40.111 A), 该记录将名字dns. umass. edu映射为一个IP地址。   

**1.DNS报文**

DNS只有这两种报文，并且，查询和回答报文有着相同的格式。

![image](https://github.com/user-attachments/assets/1c39dc89-4bb9-49d7-9450-768fe5b6293b)

* 前12个字节是首部区域，其中有几个字段。第一个字段（标识符）是一个16比特的数，用于标识该查询。这个标识符会被复制到对查询的回答报文中，以便让客户用它来匹配发送的请求和接收到的回答。 标志字段中含有若干标志。1比特的“查询/回答”标志位指出报文是查询报文 （0）还是回答报文（1）0当某DNS服务器是所请求名字的权威DNS服务器时，1比特的“权威的”标志位被置在回答报文中。如果客户（主机或者DNS服务器）在该DNS服务器没有某记录时希望它执行递归查询，将设置1比特的“希望递归”标志位。如果该DNS服务器支持递归查询，在它的回答报文中会对1比特的“递归可用”标志位置位。在该首部中，还有4个有关数量的字段，这些字段指出了在首部后的4类数据区域出现的数量。
* 问题区域包含着正在进行的查询信息。该区域包括：①名字字段，包含正在被查询的主机名字；②类型字段，指出有关该名字的正被询问的问题类型，例如主机地址是与一个名字相关联（类型A）还是与某个名字的邮件服务器相关联（类型MX）在来自DNS服务器的回答中，回答区域包含了对最初请求的名字的资源记录。前面讲过每个资源记录中有Type （如A NS CNAME和MX）字段、Value字段和TTL字段。在回答报文的回答区域中可以包含多条RR,因此一个主机名能够有多个IP地址（例如，就像本节前面讨论的冗余Web服务器）。
* 权威区域包含了其他权威服务器的记录。
* 附加区域包含了其他有帮助的记录。例如，对于一个MX请求的回答报文的回答区域包含了一条资源记录，该记录提供了邮件服务器的规范主机名。该附加区域包含一个类型A记录，该记录提供了用于该邮件服务器的规范主机名的IP地址。

**2.在DNS数据库中插入记录**   
注册域名后，需要向注册登记机构提供的你的主dns和备用dns的域名和ip，然后在你的权威dns服务器中加入你的域名配置即可。

## 2.5 P2P文件分发
![image](https://github.com/user-attachments/assets/812daf6a-9268-4489-b161-98152a092536)

## 2.6 视频流和内容分发网
### 2.6.1 因特网视频
通常压缩制作多个版本的视频，比如比特率分别为300kbps 1Mbps和3Mbps用户则能够根据他们当前可用带宽来决定观看哪个版本。
### 2.6.2 HTTP流和DASH
**经HTTP的动态适应性流**(Dynamic Adaptive Streaming over HTTP, DASH): 在DASH中，视频编码为几个不同的版本，其中每个版本具有不同的比特率，对应于不同的质量水平。客户动态地请求来自不同版本且长度为几秒的视频段数据块。当可用带宽量较高时，客户自然地选择来自高速率版本的块；当可用带宽量较低时，客户自然地选择来自低速率版本的块。客户用HTTP GET请求报文一次选择一个不同的块。   
使用DASH后，每个视频版本存储在HTTP服务器中，每个版本都有一个不同的URL HTTP服务器也有一个**告示文件**(manifest file),为每个版本提供了一个URL及其比特率。客户首先请求该告示文件并且得知各种各样的版本。然后客户通过在HTTP GET请求报文中对每块指定一个URL和一个字节范围，一次选择一块。在下载块的同时，客户也测量接收带宽并运行一个速率决定算法来选择下次请求的块。
### 2.6.3 内容分发网
1. CDN操作
当用户主机中的一个浏览器指令检索一个特定的视频（由URL标识）时，CDN必须截获该请求，以便能够：①确定此时适合用于该客户的CDN服务器集群；②将客户的请求重定向到该集群的某台服务器。大多数CDN利用DNS来截获和重定向请求；Netflix由于是自己专用的CDN，搭配自己的客户端，就不需要DNS来决定CDN路由，客户端根据自己的规则自己决定最合适的CDN。
![image](https://github.com/user-attachments/assets/771e612e-9d60-4f7e-9ba9-f76b8042a6c4)

2. 集群选择策略
任何CDN部署，其核心是**集群选择策略**(cluster selection strategy),即动态地将客户定向到CDN中的某个服务器集群或数据中心的机制。一种简单的策略是指派客户到**地理上最为邻近**(geographically closest)的集群。为了基于当前流量条件为客户决定最好的集群，CDN能够对其集群和客户之间的时延和丢包性能执行周期性的**实时测量**(real-time measurement)°

## 2.7 套接字编程：生成网络应用
### 2.7.1 UDP套接字编程
![image](https://github.com/user-attachments/assets/85b501c7-9a5e-4088-adfe-c6d1ca254663)
```python
# UDPClient.py
from socket import *
serverName = 'hostname'
serverPort = 12000
clientSocket = socket(AF_INET, SOCK_DGRAM)
message = raw_input('Input lowercase sentence:')
clientSocket.sendto(message.encode(),(serverName, serverPort))
modifiedMessage, serverAddress = clientSocket.recvfrom(2048)
print(modifiedMessage.decode())
clientSocket.close()
```
```python
UDPServer.py
from socket import *

serverPort = 12000
serverSocket = socket(AF_INET, SOCK_DGRAM)
serverSocket.bind(('', serverPort))
print ("The server is ready to receive...")

while True: 
    message, clientAddress = serverSocket.recvfrom(2048)
    print(clientAddress)
    modifiedMessage = message.decode().upper()
    serverSocket.sendto(modifiedMessage.encode(), clientAddress)
```
### 2.7.2 TCP套接字编程
![image](https://github.com/user-attachments/assets/c44e9363-89c7-4388-bc1b-78527b6419db)    
![image](https://github.com/user-attachments/assets/b396c649-c9d2-4b10-b0e9-3e62b7836ae0)   

```python
# TCPClient.py
from socket import *
serverName = 'servername'
serverPort = 12000
clientSocket = socket(AF_INETr SOCK_STREAM)
clientSocket.connect((serverName, serverPort))
sentence = raw_input('Input lowercase sentence:')
clientsocket.send(sentence.encode())
modifiedSentence = clientsocket.recv(1024)
print('From Server: ', modifiedSentence.decode())
dientSocket.close()
```

```python
# TCPServer.py
from socket import *
serverPort = 12000
serverSocket = socket(AF_INET,SOCK_STREAM)
serverSocket.bind(('', serverPort))
serverSocket.listen(1)
print(FThe server is ready to receive')
while True:
   connectionSocket, addr = serverSocket.accept()
   sentence = connectionsocket.recv(1024).decode()
   capitalizedSentence = sentence.upper()
   connectionsocket.send(capitalizedSentence.encode())
   connectionSocket.close ()
```


## 2.8 小结
在本章中，我们学习了网络应用的概念和实现两个方面。我们学习了被因特网应用普遍采用的客户-服务器模式，并且看到了该模式在HTTP SMTP POP3和DNS等协议中的使用。我们已经更为详细地学习了这些重要的应用层协议以及与之对应的相关应用(Web 文件传输、电子邮件和DNS)O我们也已学习了 P2P体系结构以及它如何应用在许多应用程序中。我们也学习了流式视频，以及现代视频分发系统是如何利用CDN的。对于面向连接的 TCP）和无连接的 UDP）端到端传输服务，我们走马观花般地学习了套接字的使用。至此，我们在分层的网络体系结构中的向下之旅已经完成了第一步

# 运输层
## 3.1 概述和运输层服务
![image](https://github.com/user-attachments/assets/f6ec3dfb-eb20-4cee-b424-81c4d0302c98)
### 3.1.1 运输层和网络层的关系
网络层提供了主机之间的逻辑通信，而运输层为运行在不同主机上的进程之间提供了逻辑通信。

### 3.1.2 因特网运输层概述
UDP和TCP还可以通过在其报文段首部中包括差错检查字段而提供完整性检查。**进程到进程的数据交付**和**差错检查**是两种最低限度的运输层服务，也是UDP所能提供的仅有的两种服务。   

TCP为应用程序提供了几种附加服务。首先，它提供**可靠数据传输**(reliable data transfer)。 通过使用流量控制、序号、确认和定时器，TCP确保正确地、按序地将数据从发送进程交付给接收进程。TCP还提供**拥塞控制**(congestion control)。

## 3.2 多路复用与多路分解
将运输层报文段中的数据交付到正确的套接字的工作称为**多路分解**(demultiplexing) 在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息(这将在以后用于分解)从而生成报文段，然后将报文段传递到网络层，所有这些工作称为**多路复用**(multiplexing) 

1.无连接的多路复用与多路分解   
一个UDP套接字是由一个二元组全面标识的，该二元组包含一个目的IP地址和一个目的端口号。因此，如果两个UDP报文段有不同的源IP地址和/或源端口号，但具有相同的目的IP地址和目的端口号，那么这两个报文段将通过相同的目的套接字被定向到相同的目的进程。

2.面向连接的多路复用与多路分解   
TCP套接字是由一个四元组（源IP地址, 源端口号，目的IP地址，目的端口号）来标识的。特别与UDP不同的是，两个具有不同源IP地址或源端口号的到达TCP报文段将被定向到两个不同的套接字，除非TCP报文段携带了初始创建连接的请求。

## 3.3 无链接运输：UDP
UDP只是做了运输协议能够做的最少工作。除了复用/分解功能及少量的差错检测外，它几乎没有对IP增加别的东西。   

有许多应用更适合用UDP,原因主要以下几点：   
* 关于发送什么数据以及何时发送的应用层控制更为精细
* 无须连接建立
* 无连接状态
* 分组首部开销小

UDP无拥塞控制可能会导致高丢包率和挤垮TCP会话问题。  

使用UDP的应用是可能实现可靠数据传输的。需要应用做更多的工作。

### 3.3.1 UDP报文段结构
UDP首部只有4个字段，每个字段由两个字节组成。长度字段指示了在UDP报文段中的字节数（首部加数据）。   
![image](https://github.com/user-attachments/assets/847bfae9-a967-4b89-ac6d-b3b3c5b78080)

### 3.3.2 UDP检验和
举例来说，假定我们有下面3个16比特的字：   

![image](https://github.com/user-attachments/assets/c03ec14e-f62c-487c-a702-888058eb5114)    

注意到最后一次加法有溢出，它要被回卷。反码运算就是将所有的0换成1, 所有的1转换成0。因此,该和0100101011000010的反码运算结果是1011010100111101,这就变为了检验和。如果该分组中没有引入差错，则显然在接收方处该和将是111111111111111。如果这些比特之一是0,那么我们就知道该分组中已经出现了差错。   

虽然UDP提供差错检测，但它对差错恢复无能为力。

## 3.4 可靠数据传输原理
### 3.4.1 构造可靠数据传输协议
1. 经完全可靠信道的可靠数据传输：rdt1.0   
   <img width="392" alt="image" src="https://github.com/user-attachments/assets/3b34ee78-87f0-47b7-9c28-38d719ec5f36">
2. 经具有比特差错信道的可靠数据传输：rdt2.0   
基于重传机制的可靠数据传输协议称为**自动重传请求**(Automatic Repeat reQuest, ARQ)协议。重要的是，ARQ协议中还需要另外三种协议功能来处理存在比特差错的情况：
    * 差错检测
    * 接收方反馈
    * 重传
<img src="https://github.com/user-attachments/assets/afeca2f6-f32e-4b80-be2c-6259d6de040a" width="700px"/>

rdt2.0有个严重问题，就是没有考虑ACK或NAK分组受损的可能性。解决这个新问题的一个简单方法（几乎所有现有的数据传输协议中，包括TCP,都采用了这种方法）是在数据分组中添加一新字段，让发送方对其数据分组编号，即将发送数据分组的**序号**（sequence number）放在该字段。于是，接收方只需要检查序号即可确定收到的分组是否一次重传。   

rdt2.1引入了序号：   
<img width="700" alt="image" src="https://github.com/user-attachments/assets/2a37c8eb-0807-4e21-98c3-886c9e5cc1e2">
<img width="700" alt="image" src="https://github.com/user-attachments/assets/df841e7a-6ce7-4ba0-ad9d-3a79dd4b4563">   
 
rdt2.2去掉了NAK，使用ACK带编号来解决：   
<img width="700" alt="image" src="https://github.com/user-attachments/assets/211ad274-80e5-4ffc-8fde-0e6465cc3392">   
<img width="700" alt="image" src="https://github.com/user-attachments/assets/98cc37a9-a782-40db-ad80-2eb4e4644a86">   

3. 经具有比特差错的丢包信道的可靠数据传输：rdt3.0   
应付丢包的方法是重传，还有要确定好超时的时间，多次发送要处理好晚到的ACK   
<img width="700" alt="image" src="https://github.com/user-attachments/assets/bee29840-f366-4158-bc3f-cc9f9a262f7d">  

<img width="661" alt="image" src="https://github.com/user-attachments/assets/18d3e659-19ff-4e44-9bcf-43c1c7087a1b">   

<img width="661" alt="image" src="https://github.com/user-attachments/assets/3dfb2cf1-29de-4e07-a112-e1b60cc0f55a">

### 3.4.2 流水线可靠数据传输协议
流水线的引入能极大提高传输性能。不等待ack就发送下一个分组，需要：   
* 必须增加序号范围，因为每个输送中的分组（不计算重传的）必须有一个唯一的序号，而且也许有多个在输送中的未确认报文。
* 协议的发送方和接收方两端也许不得不缓存多个分组。发送方最低限度应当能缓冲那些已发送但没有确认的分组。如下面讨论的那样，接收方或许也需要缓存那些已正确接收的分组。
* 所需序号范围和对缓冲的要求取决于数据传输协议如何处理丢失、损坏及延时过大的分组。解决流水线的差错恢复有两种基本方法是：**回退N步**(Go Back N,GBN)和**选择重传**(Selective Repeat, SR)

<img width="621" alt="image" src="https://github.com/user-attachments/assets/51a6a34b-3ce8-4d7a-a1c4-15a3df75b9c8">   

### 3.4.3 回退N步
在**回退N步**(GBN）协议中，允许发送方发送多个分组（当有多个分组可用时）而不需等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数N。N常被称为**窗口长度**(window size), GBN协议也常被称为滑动窗口协议(sliding-window protocol）。

大于或等于base+N的序号是不能使用的，直到当前流水线中未被确认的分组（特别是序号为base的分组）已得到确认为止。   
![image](https://github.com/user-attachments/assets/06251422-66b9-4fc9-92e1-538921806dff)      


GBN发送方必须响应三种类型的事件：   
* **上层的调用**：当上层调用rdt.send()时，发送方首先检查发送窗口是否已满，即是否有N个已发送但未被确认的分组。如果窗口未满，则产生一个分组并将其发送,并相应地更新变量。如果窗口已满，发送方只需将数据返回给上层，隐式地指示上层该窗口已满。然后上层可能会过一会儿再试。在实际实现中，发送方更可能缓存（并不立刻发送）这些数据，或者使用同步机制（如一个信号量或标志）允许上层在仅当窗口不满时才调用rdt.send()。
* **收到一个ACK**： 在GBN协议中，对序号为几的分组的确认采取累积确认（cumulative acknowledgment）的方式，表明接收方已正确接收到序号为n的以前且包括n在内的所有分组。
* **超时事件**。协议的名字“回退N步”来源于出现丢失和时延过长分组时发送方的行为。就像在停等协议中那样，定时器将再次用于恢复数据或确认分组的丢失。如果出现超时，发送方重传所有已发送但还未被确认过的分组。图3.20中的发送方仅使用一个定时器，它可被当作是最早的已发送但未被确认的分组所使用的定时器。如果收到一个ACK,但仍有已发送但未被确认的分组，则定时器被重新启动。如果没有已发送但未被确认的分组，停止该定时器。

<img width="800" alt="image" src="https://github.com/user-attachments/assets/8212cf0c-5e57-4796-b102-a7d5a51b06d2">     

在GBN中，接收方的动作也很简单。如果一个序号为n的分组被正确接收到，并且按序（即上次交付给上层的数据是序号为n-1的分组），则接收方为分组“发送一个ACK,并将该分组中的数据部分交付到上层。在所有其他情况下，接收方丢弃该分组，并为最近按序接收的分组重新发送ACK。注意到因为一次交付给上层一个分组，如果分组k已接收并交付，则所有序号比k小的分组也已经交付。因此，使用累积确认是GBN—个自然的选择。   

在GBN协议中，接收方丢弃所有失序分组。尽管丢弃一个正确接收（但失序）的分组有点愚蠢和浪费，但这样做是有理由的。前面讲过，接收方必须按序将数据交付给上层。假定现在期望接收分组n, 而分组n+1却到了。因为数据必须按序交付，接收方可能缓存（保存）分组n+1,然后，在它收到并交付分组n后，再将该分组交付到上层。然而，如果分组n丢失，则该分组及分组n+1最终将在发送方根据GBN重传规则而被重传。因此，接收方只需丢弃分组n+1即可。   

<img width="800" alt="image" src="https://github.com/user-attachments/assets/29926970-d5e4-4724-b3b0-2ca253a46590">     

图3-22给岀了窗口长度为4个分组的GBN协议的运行情况:   

![image](https://github.com/user-attachments/assets/527ff0a0-249d-4619-b900-3bd26db9b18b)

### 3.4.4 选择重传
![image](https://github.com/user-attachments/assets/b4934dd5-a563-4f18-8669-480fd3ed483b)   

SR发送方的事件与动作：   
1. **从上层收到数据**。当从上层接收到数据后，SR发送方检查下 个可用于该分组的序号。如果序号位于发送方的窗口内，则将数据打包并发送；否则就像在GBN中一样，要么将数据缓存，要么将其返回给上层以便以后传输。
2. **超时**。定时器再次被用来防止丢失分组。然而，现在每个分组必须拥有其自己的逻辑定时器，因为超时发生后只能发送一个分组。可以使用单个硬件定时器模拟多个逻辑定时器的操作［Varghese 1997］。
3. **收到ACK** 如果收到ACK,倘若该分组序号在窗口内，则SR发送方将那个被确认的分组标记为已接收。如果该分组的序号等于send_base,则窗口基序号向前移动到具有最小序号的未确认分组处。如果窗口移动了并且有序号落在窗口内的未发送分组，则发送这些分组。

SR接收方的事件与动作：
1. **序号在［rcv_base, rcv_base + N - 1]内的分组被正确接收**：在此情况下，收到的分组落在接收方的窗口内，一个选择ACK被回送给发送方。如果该分组以前没收到过，则缓存该分组。如果该分组的序号等于接收窗口的基序号（图3.23中的rcv_base）.则该分组以及以前缓存的序号连续的（起始于rcv_base的）分组交付给上层。然后，接收窗口按向前移动分组的编号向上交付这些分组。举例子来说，考虑一下图3.26。当收到一个序号为rcv_base=2的分组时，该分组及分组3、4、5可被交付给上层。
2. **序号在［rcv_base-N, rcv_base - 1］内的分组被正确收到**：在此情况下，必须产生一个ACK,即使该分组是接收方以前已确认过的分组。
3. **其他情况**：忽略该分组。

何对于SR协议而言，窗口长度必须小于或等于序号空间大小的一半，从而避免下图的窗口太大困境：   
![image](https://github.com/user-attachments/assets/1780b4e5-1a67-4d2e-98ba-705860eb3170)

**小结**：   
![image](https://github.com/user-attachments/assets/1dc858d8-a219-4cf8-a25c-2e96d74381c0)   

由于网络是网状接口，为了避免乱序分组出现问题，实际应用中采用的方法是，确保一个序号不被重新使用，直到发送方“确信”任何先前发送的序号为x的分组都不再在网络中为止。通过假定一个分组在网络中的“存活”时间不会超过某个固定最大时间量来做到这一点。在高速网络的TCP扩展中，最长的分组寿命被假定为大约3分钟。

## 3.5 面向连接的运输：TCP
### 3.5.1 TCP连接
TCP被称为是**面向连接**的（connection-oriented）, 它们必须相互发送某些预备报文段，以建立确保数据传输的参数。作为TCP连接建立的一部分，连接的双方都将初始化与TCP连接相关的许多TCP状态变量。TCP的“连接”是一条逻辑连接，中间路由器对TCP连接完全视而不见，它们看到的是数据报文，而不是连接。TCP连接也总是**点对点**（point-to-point）的，即在单个发送方与单个接收方之间的连接。所谓“多播”，即在一次发送操作中，从一个发送方将数据传送给多个接收方，这种情况对TCP来说是不可能的。   

TCP可从缓存中取出并放入报文段中的数据数量受限于**最大报文段长度**（Maximum Segment Size,MSS）。MSS通常根据最初确定的由本地发送主机发送的最大链路层帧长度（即所谓的**最大传输单元**（Maximum Transmission Unit, MTU））来设置。   

以太网和PPP链路层协议都具有1500字节的MTU，因此MSS的典型值为1460字节。   

![image](https://github.com/user-attachments/assets/6f7daeb3-ddf8-45fe-94bc-21908ae5858b)

### 3.5.2 TCP报文段结构
![image](https://github.com/user-attachments/assets/368de6bb-a903-4e9f-84b5-1abec9cb6f9d)   

* **32比特的序号字段(sequence number field)和32比特的确认号字段(acknowledgment number field)**： 这些字段被TCP发送方和接收方用来实现可靠数据传输服务。
* **16比特的接收窗口字段(receive window field)**,该字段用于流量控制。该字段用于指示接收方愿意接受的字节数量。
* **4比特的首部长度字段(header length field)**, 该字段指示了以32比特的字为单位的TCP首部长度。由于TCP选项字段的原因，TCP首部的长度是可变的。(通常,选项字段为空，所以TCP首部的典型长度是20字节。)
* **可选与变长的选项字段(options field)**,该字段用于发送方与接收方协商最大报文段长度(MSS)时，或在高速网络环境下用作窗口调节因子时使用。首部字段中还定义了一个时间戳选项。
* **6比特的标志字段(flag field)**。**ACK**比特用于指示确认字段中的值是有效的，即该报文段包括一个对已被成功接收报文段的确认。**RST**、**SYN**和**FIN**比特用于连接建立和拆除。在明确拥塞通告中使用了**CWR**和**ECE**比特。当**PSH**比特被置位时，就指示接收方应立即将数据交给上层。最后，**URG**比特用来指示报文段里存在着被发送端的上层实体置为“紧急”的数据。紧急数据的最后一个字节由16比特的**紧急数据指针字段**(urgent data pointer field)指出。当紧急数据存在并给出指向紧急数据尾指针的时候，TCP必须通知接收端的上层实体。(**在实践中，PSH URG和紧急数据指针并没有使用。为了完整性起见，我们才提到这些字段。**)


1. 序号和确认号
* TCP协议不是按报文来编号的，是按个字节编号的。
* 确认号是主机正在等待的数据的下一个字节序号。
* 报文段失序到达如何处理TCP RFC没有明确定义，一般是保留，等待缺少的字节到达
* 一条TCP连接的双方均可随机地选择初始序号。这样做可以减少将那些仍在网络中存在的来自两台主机之间先前已终止的连接的报文段，误认为是后来这两台主机之间新建连接所产生的有效报文段的可能性（它碰巧与旧连接使用了相同的端口号）

2. Telnet: 序号和确认号的一个学习案例   
![image](https://github.com/user-attachments/assets/901ab87c-fdce-4d82-8000-b64166bbfd51)

### 3.5.3 往返时间的估计与超时
**1.估计往返时间**   
在任意时刻，仅为一个已发送的但目前尚未被确认的报文段估计SampleRTT,从而产生一个接近每个RTT的新SampleRTT值。另外，TCP决不为已被重传的报文段计算SampleRTT 它仅为传输一次的报文段测量SampleRTT
TCP维持一个SampleRTT均值（称为EstimatedRTT）。一旦获得一个新SampleRTT时，TCP就会根据下列公式来更新EstimatedRTT:
```
EstimatedRTT = (1-a)*EstimatedRTT + a*EstimatedRTT
```
a推荐值是a=0.125   
从统计学观点讲，这种平均被称为**指数加权移动平均**（Exponential Weighted Moving Average, EWMA）。
![image](https://github.com/user-attachments/assets/5855729e-c479-492b-9939-f0b2eaa5dd53)

RTT偏差DevRTT,用于估算SampleRTT 一般会偏离EstimatedRTT的程度：
```
DevRTT = (1-b)*DevRtt + b*|SampleRTT-EstimatedRTT|
```
b的推荐值为0.25

**2.设置和管理重传超时间隔**   
超时时间应该是指为大于等于EstimatedRTT，需要在EstimatedRTT加上一定余量，这个余量就是用DevRTT评估：
```
TimeoutInterval = EstimatedRTT + 4 * DevRTT
```
推荐的初始Timeoutinterval值为1秒。同时，当出现超时后，TimeoutInterval值将加倍。

### 3.5.4 可靠数据传输
TCP发送方有3个与发送和重传有关的主要事件：从上层应用程序接收数据；定时器超时和收到ACK:   
1. TCP从应用程序接收数据，将数据封装在一个报文段中，并把该报文段交给IP。注意到每一个报文段都包含一个序号，序号是该报文段第一个数据字节的字节流编号。如果定时器还没有为某些其他报文段而运行，则当报文段被传给IP时，TCP就启动该定时器。（将定时器想象为与最早的未被确认的报文段相关联）。
2. TCP通过重传引起超时的报文段来响应超时事件。然后TCP重启定时器
3. 到达一个来自接收方的确认报文段 ACK，TCP将ACK的值y与它的变量SendBase进行比较。TCP状态变量SendBase是最早未被确认的字节的序号。TCP采用累积确认，所以y确认了字节编号在y之前的所有字节都已经收到。如果y > SendBase,则该ACK是在确认一个或多个先前未被确认的报文段。因此发送方更新它的SendBase变量；如果当前有未被确认的报文段，TCP还要重新启动定时器。

![image](https://github.com/user-attachments/assets/1510213c-4f91-47a5-8797-65713071392f)

**一些有趣情况**   
![image](https://github.com/user-attachments/assets/4e665cea-3055-4abe-a5bc-a5a1b43bcb9c)
![image](https://github.com/user-attachments/assets/85063aef-19fc-46d6-941d-4e97fc8b852a)

**超时间隔加倍**   
每次TCP重传时都会将下一次的超时间隔设为先前值的两倍，而不是用从EstimatedRTT和DevRTT推算出的值；然而，每当定时器在另两个事件（即收到上层应用的数据和收到ACK）中的任意一个启动时，Timeoutinterval由最近的EstimatedRTT值与DevRTT值推算得到

**快速重传**
冗余ACK（duplicate ACK）就是再次确认某个报文段的ACK,而发送方先前已经收到对该报文段的确认。一旦收到3个冗余ACK, TCP就执行**快速重传**（fast retransmit）。
![image](https://github.com/user-attachments/assets/7f60953c-289e-4ae6-9749-b178f00852ba)      
![image](https://github.com/user-attachments/assets/d7796f18-81bd-4cd1-a624-d76b54e44314)    
![image](https://github.com/user-attachments/assets/9fa6b93f-db84-41b9-9f90-4f7563916726)

**是回退N步还是选择重传**
对TCP提岀的一种修改意见是所谓的**选择确认**(selective acknowledgment)。它允许TCP接收方有选择地确认失序报文段，而不是累积地确认最后一个正确接收的有序报文段。TCP的差错恢复机制也许最好被分类为GBN协议与SR协议的混合体。

### 3.5.5 流量控制
TCP为它的应用程序提供了**流量控制服务**(flow control service)以消除发送方使接收方缓存溢岀的可能性。TCP发送方也可能因为IP网络的拥塞而被遏制；这种形式的发送方的控制被称为**拥塞控制**(congestion control)。   
TCP通过让发送方维护一个称为接收窗口(receive window)的变量来提供流量控制。通俗地说，接收窗口用于给发送方一个指示一 该接收方还有多少可用的缓存空间。   
![image](https://github.com/user-attachments/assets/d84620e6-4d28-435d-bdee-e5ecfcc5c359)

### 3.5.6 TCP连接管理
**创建**：客户中的TCP会用以下方式与服务器中的TCP建立一条TCP连接:   
1. 第一步：客户端的TCP首先向服务器端的TCP发送一个特殊的TCP报文段。该报文段中不包含应用层数据。但是在报文段的首部中的一个标志位（即SYN比特）被置为1。因此，这个特殊报文段被称为SYN报文段。另外，客户会随机地选择一个初始序号（client_isn），并将此编号放置于该起始的TCP SYN报文段的**序号**字段中。该报文段会被封装在一个IP数据报中，并发送给服务器。
2. 第二步：一旦包含TCP SYN报文段的IP数据报到达服务器主机，服务器会从该数据报中提取出TCP SYN报文段，为该TCP连接分配TCP缓存和变量，并向该客户TCP发送允许连接的报文段。这个允许连接的报文段也不包含应用层数据。但是，在报文段的首部却包含3个重要的信息。首先，SYN比特被置为1。其次，该TCP报文段首部的确认号字段被置为client_isn + 1。最后，服务器选择自己的初始序号（server_isn），并将其放置到TCP报文段首部的**序号**字段中。这个允许连接的报文段实际上表明了：“我收到了你发起建立连接的SYN分组，该分组带有初始序号client_isn。我同意建立该连接。我自己的初始序号是server_isn。”该允许连接的报文段被称为SYNACK报文段（SYNACK segment）。
3. 第三步：在收到SYNACK报文段后，客户也要给该连接分配缓存和变量。客户主机则向服务器发送另外一个报文段；这最后一个报文段对服务器的允许连接的报文段进行了确认（该客户通过将值server_isn + 1放置到TCP报文段首部的**确认**字段中来完成此项工作）。因为连接已经建立了，所以该SYN比特被置为0。*该三次握手的第三个阶段可以在报文段负载中携带客户到服务器的数据*(待验证)。
<img width="400" alt="image" src="https://github.com/user-attachments/assets/5b8034b4-edbe-4881-a927-c5096afef45e">

**关闭**：参与一条TCP连接的两个进程中的任何一个都能终止该连接。   
客户应用进程发出一个关闭连接命令。这会引起客户TCP向服务器进程发送一个特殊的TCP报文段。这个特殊的报文段让其首部中的一个标志位即FIN比特被设置为1。当服务器接收到该报文段后，就向发送方回送一个确认报文段。然后，服务器发送它自己的终止报文段，其FIN比特被置为1。最后，该客户对这个服务器的终止报文段进行确认。此时，在两台主机上用于该连接的所有资源都被释放了。   
<img width="400" alt="image" src="https://github.com/user-attachments/assets/13a0462a-d98c-484b-9ee1-9171e99549fc">

**TCP状态**：   
在TIMEWAIT状态中所消耗的时间是与具体实现有关的，而典型的值是30秒、1分钟或2分钟。 经过等待后，连接就正式关闭，客户端所有资源（包括端口号）将被释放   
<img width="400" alt="image" src="https://github.com/user-attachments/assets/c842f687-9a2a-430e-a3bd-eefaa505f3e8">

<img width="400" alt="image" src="https://github.com/user-attachments/assets/30655195-9f22-4994-90a4-c502cf0b571e">

**nmap工作原来**   
* 源主机从目标主机接收到一个TCP SYNACK报文段。因为这意味着在目标主机上一个应用程序使用TCP端口 6789运行，nmap返回“打开”。
* 源主机从目标主机接收到一个TCP RST报文段。这意味着该SYN报文段到达了目标主机，但目标主机没有运行一个使用TCP端口 6789的应用程序。但攻击者至少知道发向该主机端口 6789的报文段没有被源和目标主机之间的任何防火墙所阻挡。
* 源什么也没有收到。这很可能表明该SYN报文段被中间的防火墙所阻挡，无法到达目标主机。

## 3.6 拥塞控制原理
### 3.6.1 拥塞原因与代价
拥塞网络的代价： 
* 当分组的到达速率接近链路容量时，分组经历巨大的排队时延。
* 发送方必须执行重传以补偿因为缓存溢出而丢弃（丢失）的分组。
* 发送方在遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本。
* 当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了。

### 3.6.2 拥塞控制方法
* 端到端拥塞控制：端系统也必须通过对网络行为的观察来推断。
* 网络辅助的拥塞控制：网络层的反馈，有直接反馈和接收方反馈，接收方反馈需要经过一个完整往返周期。
<img width="654" alt="image" src="https://github.com/user-attachments/assets/8242bc7a-98bf-4178-b8c5-b648d98749dd">

## 3.7 TCP拥塞控制
运行在发送方的TCP拥塞控制机制跟踪变量，即拥塞窗口（congestion window)。拥塞窗口表示为`cwnd`, 它对一个TCP发送方能向网络中发送流量的速率进行了限制。   
TCP使用下列指导性原则：   
* 一个丢失的报文段表意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率。
* 一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当对先前未确认报文段的确认到达时，能够增加发送方的速率。
* 带宽探测。逐步加快传输速度，根据ack调整速度

**TCP拥塞控制算法**
<img width="792" alt="image" src="https://github.com/user-attachments/assets/b1401910-7dcd-4746-910e-44d722e61dad">   

<img width="402" alt="image" src="https://github.com/user-attachments/assets/bfedfeab-da92-4c31-a026-caa43d3d9c34">

### 3.7.1 公平性
* 完美情况下，即所有TCP的开始时间，RTT等参数全部相同的时候，TCP的AIMD(加性增，乘性减)算法还算是公平的，会逐步趋于平均；但是实际情况是较小RTT的TCP会拥有更大的吞吐量。
* 由于UDP没有拥塞算法，所以对于TCP来说，UDP是不公平的，UDP会压制TCP
* 并行TCP会占据更多的带宽比例，所以浏览器的多开TCP连接整体来说是不公平的


<img width="400" alt="image" src="https://github.com/user-attachments/assets/b3079179-db17-4dfc-9196-5dc4a061fb34">


### 3.7.2 明确拥塞通告：网络辅助拥塞控制
IP和TCP的扩展方案［RFC 3168］已经提出并已经实现和部署，该方案允许网络明确向TCP发送方和接收方发出拥塞信号。这种形式的网络辅助拥塞控制称为**明确拥塞通告**(Explicit Congestion Notification, ECN）。   

<img width="400" alt="image" src="https://github.com/user-attachments/assets/284b4028-4e76-451e-adba-47a54d740f68">

## 3.8 小结
本章我们首先学习了运输层协议能够向网络应用程序提供的服务。在一个极端，运输层协议非常简单，并向应用程序不提供不必要的服务，而仅向通信进程提供多路复用/分解的功能。因特网中的UDP协议就是这样一种不提供不必要服务的运输层协议。在另一个极端，运输层协议能够向应用程序提供各种各样的保证，例如数据的可靠交付、时延保证和带宽保证。无论如何，运输层协议能够提供的服务经常受下面网络层协议服务模型的限制。如果网络层协议不能向运输层报文段提供时延或带宽保证，那么运输层协议就不能向进程间发送的报文提供时延或带宽保证。   

在3.4节中，我们学习了运输层协议能够提供可靠数据传输，即使下面的网络层是不可靠的。我们看到了提供可靠的数据传送会遇到许多微妙的问题，但都可以通过精心地结合确认、定时器、重传以及序号机制来完成任务。   

尽管在本章中我们包含了可靠数据传送，但是我们应该理解在链路层、网络层、运输层或应用层协议中都可以提供可靠数据传送。该协议栈中上面4层的任意一层都可以实现确认、定时器、重传以及序号，能够向其上层提供可靠数据传送。事实上，在过去数年中，工程师以及计算机科学家们已经独立地设计并实现了提供可靠数据传送的链路层、网络层、运输层以及应用层协议（虽然这些协议中的许多已经销声匿迹了）。   

在3.5节中，我们详细地研究了TCP协议，它是因特网中面向连接和可靠的运输层协议。我们知道TCP是非常复杂的，它涉及了连接管理、流量控制、往返时间估计以及可靠数据传送。事实上，TCP比我们描述的要更为复杂，即我们有意地避而不谈在各种TCP实现版本中广泛实现的各种TCP补丁、修复和改进。然而，所有这些复杂性都对网络层应用隐藏了起来。如果某主机上的客户希望向另一台主机上的服务器可靠地发送数据，它只需要打开对该服务器的一个TCP套接字，然后将数据注入该套接字。客户-服务器应用程序则乐于对TCP的复杂性视而不见。

在3.6节中，我们从广泛的角度研究了拥塞控制，在3.7节中我们阐述了 TCP是如何实现拥塞控制的。我们知道了拥塞控制对于网络良好运行是必不可少的。没有拥塞控制,网络很容易出现死锁，使得端到端之间很少或没有数据能被传输。在3.7节中我们学习了TCP实现的一种端到端拥塞控制机制，即当TCP连接的路径上判断不拥塞时，其传输速率就加性增；当岀现丢包时，传输速率就乘性减。这种机制也致力于做到每一个通过拥塞链路的TCP连接能平等地共享该链路带宽。我们也深入探讨了 TCP连接建立和慢启动对时延的影响。我们观察到在许多重要场合，连接建立和慢启动会对端到端时延产生严重影响。我们再次强调，尽管TCP在这几年一直在发展，但它仍然是一个值得深入研究的领域，并且在未来的几年中还可能持续演化。

在本章中我们对特定因特网运输协议的讨论集中在UDP和TCP上，它们是因特网运输层的两匹“驮马”。然而，对这两个协议的二十多年的经验已经使人们认识到，这两个协议都不是完美无缺的。研究人员因此在忙于研制其他的运输层协议，其中的几种现在已经成为IETF建议的标准。虽然这些协议明确地提供了超过TCP和UDP的强化能力，但是多年来已经证明了 TCP和UDP自身是“足够好”的。是否“更好”将胜岀“足够好”，这将取决于技术、社会和商业考虑的复杂组合。

# 网络层：数据平面
## 4.1 网络层概述
### 4.1.1 转发和路由选择：数据平面和控制平面
* **转发**(forwarding)是指将分组从一个输入链路接口转移到适当的输出链路接口的**路由器本地动作**。转发发生的时间尺度很短(通常为几纳秒)，因此通常用硬件来实现。
* **路由选择**(routing)是指确定分组从源到目的地所采取的端到端路径的网络范围处理过程。计算这些路径的算法被称为**路由选择算法**(routing algorithm)。路由选择发生的时间尺度长得多(通常为几秒)，因此通常用软件来实现。

![image](https://github.com/user-attachments/assets/6e536cb9-3866-40d7-8c68-cabde6308a33)


1.控制平面：传统的方法    
一台路由器中的路由选择算法与在其他路由器中的路由选择算法通信(通过根据路由选择协议交换包含路由选择信息的路由选择报文)，以计算出它的转发表的值。   

2.控制平面：SDN方法   
下图中的控制平面方法是软件定义网络(Software-Defined Networking, SDN）的本质   
![image](https://github.com/user-attachments/assets/dcb854b2-24a3-4fe5-86ab-e43e56671b4a)

# 4.1.2 网络服务模型
因特网的网络层提供了单一的服务，称为**尽力而为服务**（best effort service）。不确保交付，不确保延时，不确保有序，不确保带宽，无安全性。

# 4.2 路由器工作原理
![image](https://github.com/user-attachments/assets/b814a000-40fa-4a3f-b15d-2d4fc66ab022)

### 4.2.1 输入端口处理和基于目的地转发

![image](https://github.com/user-attachments/assets/c605862f-51ee-431f-906c-06df3e5918e4)

### 4.2.2 交换

![image](https://github.com/user-attachments/assets/ddb6c8f0-42d2-4080-a956-9b083b94d8f9)

### 4.2.3 输出端口处理

![image](https://github.com/user-attachments/assets/460ff4c8-fd72-4a5b-aa47-a21dca828bd3)

### 4.2.4 何处出现排队
当路由无内存可用于存储到达的分组时将会出现**丢包**（packet loss）。   

1. 输入排队：下图叫作输入排队交换机中的**线路前部**（Head-Of-the-Line, HOL）**阻塞**   
<img width="552" alt="image" src="https://github.com/user-attachments/assets/5a03454d-864b-43f4-a856-c376bd5cc0b0">

2. 输出排队
当路由内存不够：要么丢弃到达的分组（采用一种称为**弃尾**（drop tail）的策略），要么删除一个或多个已排队的分组为新来的分组腾出空间。在某些情况下，在缓存填满之前便丢弃一个分组（或在其首部加上标记）的做法是有利的，这可以向发送方提供一个拥塞信号。
<img width="535" alt="image" src="https://github.com/user-attachments/assets/b7ff680f-a977-40c0-9f88-7b2211f4b1e7">

### 4.2.5 分组调度
1. 先进先出
<img width="400" alt="image" src="https://github.com/user-attachments/assets/72e09c8a-822c-45f1-84aa-892de8e0f117">

3. 优先权排队
<img width="400" alt="image" src="https://github.com/user-attachments/assets/51fc6b74-0fc5-45d3-a5f1-27f97e070e36">

5. 循环和加权公平排队
<img width="400" alt="image" src="https://github.com/user-attachments/assets/9fd5cc11-257d-479e-85d4-5a91e11c4753">

## 4.3 网际协议：IPv4、寻址、IPv6及其他
### 4.3.1 IPv4数据报格式
IPv4数据报中的关键字段如下：   
* **版本**（号）。这4比特规定了数据报的IP协议版本。通过查看版本号，路由器能够确定如何解释IP数据报的剩余部分。
* **首部长度**。因为一个IPv4数据报可包含一些可变数量的选项（这些选项包括在IPv4数据报首部中），故需要用这4比特来确定1P数据报中载荷实际开始的地方。
* **服务类型**（TOS）。比特包含在IPv4首部中，以便使不同类型的IP数据报（例如，一些特别要求低时延、高吞吐量或可靠性的数据报）能相互区别开来。
* **数据报长度**。这是IP数据报的总长度（首部加上数据），以字节计。因为该字段长为16比特，所以IP数据报的理论最大长度为65 535字节。然而，数据报很少有超过1500字节的，该长度使得IP数据报能容纳最大长度以太网帧的载荷字段。
* **标识、标志、片偏移**。这三个字段与所谓IP分片有关。有趣的是，新版本的IP （即IPv6）不允许在路由器上对分组分片。
* **寿命**。（Time To Live, TTL）字段用来确保数据报不会永远（如由于长时间的路由选择环路）在网络中循环。每当一台路由器处理数据报时，该字段的值减1。若TTL字段减为0,则该数据报必须丢弃。
* **协议**。该字段通常仅当一个IP数据报到达其最终目的地时才会有用。该字段值指示了IP数据报的数据部分应交给哪个特定的运输层协议。例如，值为6表明数据部分要交给TCP,而值为17表明数据要交给UDP
* 首部检验和。首部检验和用于帮助路由器检测收到的IP数据报中的比特错误。为什么TCP/IP在运输层与网络层都执行差错检测？这种重复检测有几种原因。首先，注意到在IP层只对IP首部计算了检验和，而TCP/UDP检验和是对整个TCP/UDP报文段进行的。其次，TCP/UDP与IP不一定都必须属于同一个协议栈。原则上,TCP能够运行在一个不同的协议（如ATM）上,而IP能够携带不一定要传递给TCP/UDP的数据。
* **源和目的IP地址**。
* **选项**。选项字段允许IP首部被扩展。在IPv6首部中已去掉了IP选项
* **数据**（有效载荷）。承载TCP/UDP报文，也可以承载ICMP报文。   
<img width="543" alt="image" src="https://github.com/user-attachments/assets/e927f1a2-d7ea-4b12-adb2-b6906f46649d">

### 4.3.2 IPv4数据报分片
并不是所有链路层协议都能承载相同长度的网络层分组。例如，以太网帧能够承载不超过1500字节的数据，而某些广域网链路的帧可承载不超过576字节的数据。一个链路层帧能承载的最大数据量叫作**最大传送单元**（Maximum Transmission Unit, MTU）   

为坚持网络内核保持简单的原则，IPv4的设计者决定将数据报的重新组装工作放到端系统中，而不是放到网络路由器中。   

利用ip报文中的标识、标志和片偏移字段实现分片。   

<img width="572" alt="image" src="https://github.com/user-attachments/assets/dd324212-39b4-464f-9fc7-8357c6063b53">

### 4.3.3 IPv4 编址
主机与物理链路之间的边界叫作**接口**（interface）。从技术上讲，一个IP地址与一个接口相关联，而不是与包括该接口的主机或路由器相关联。     

<img width="450" alt="image" src="https://github.com/user-attachments/assets/3ad8b709-7235-4d14-9962-0f81f27a6b21">   

<img width="450" alt="image" src="https://github.com/user-attachments/assets/a3dca95f-85dc-413e-8d46-236ad68c29a1">      

<img width="450" alt="image" src="https://github.com/user-attachments/assets/5b91718d-48d6-41ef-822c-227f2ebc43c7">      

因特网的地址分配策略被称为**无类别域间路由选择**(Classless Inlerdomain Routing,CIDR)。在CIDR被采用之前，IP地址的网络部分被限制为长度为8、16或24比特，这是一种称为分类编址（classful addressing）的编址方案，这是因为具有8、16和24比特子网地址的子网分别被称为A、B和C类网络。   


主机或子网最初是如何得到它们的地址：
1. 获取一块地址：为了获取一块IP地址用于一个组织的子网内，某网络管理员也许首先会与他的ISP联系，该ISP可能会从已分给它的更大地址块中提供一些地址。
2. 获取主机地址：动态主机配置协议（Dynamic Host Configuration, DHCP）
<img width="500" alt="image" src="https://github.com/user-attachments/assets/0a9aaed0-2a2e-45dc-82e5-59b12393c6d2">  

DHCP协议是一个4个步骤的过程，下图中，yiaddr（表示“你的因特网地址”之意)
<img width="468" alt="image" src="https://github.com/user-attachments/assets/2753803c-c6d3-44fa-95aa-61ce1180896c">
1. DHCP服务器发现。一台新到达的主机的首要任务是发现一个要与其交互的DHCP服务器。这可通过使用DHCP发现报文 DHCP discover message）来完成，客户在UDP分组中向端口67发送该发现报文。
2. DHCP服务器提供。DHCP服务器收到一个DHCP发现报文时，用DHCP提供报文(DHCP offer message)向客户做出响应，该报文向该子网的所有节点广播，仍然使用IP广播地址255.255.255.255
3. DHCP请求。新到达的客户从一个或多个服务器提供中选择一个，并向选中的服务器提供用DHCP请求报文(DHCP request mess昭e)进行响应，回显配置的参数。
4. DHCP ACK。服务器用 DHCP ACK 报文(DHCP ACK message)寸 DHCP 请求报文进行响应，证实所要求的参数

### 4.3.4 网络地址转换
NAT在近年来已得到了广泛的应用。但是NAT并非没有贬低者。首先，有人认为端口号是用于进程寻址的，而不是用于主机寻址的。其次，纯粹的体系结构者提出了更为“原理性的”反对NAT的意见。这时，关注焦
点在于路由器是指第三层（即网络层）设备，并且应当处理只能达到网络层的分组。NAT违反主机应当直接彼此对话这个原则，没有干涉节点修改1P地址，更不用说端口号。   
<img width="600" alt="image" src="https://github.com/user-attachments/assets/523a9324-49e6-4f7d-9a48-18796efb3adb">

### 4.3.5 IPv6
IPv6中定义的字段:   
* **版本**。该4比特字段用于标识IP版本号。毫不奇怪，IPv6将该字段值设为6。意到将该字段值置为4并不能创建一个合法的IPv4数据报。
* **流量类型**。该8比特字段与我们在IPv4中看到的TOS字段的含义相似。
* **流标签**。该20比特的字段用于标识一条数据报的流，能够对一条流中的某些数据报给出优先权，或者它能够用来对来自某些应用（例如IP话音）的数据报给岀更高的优先权，以优于来自其他应用（例如SMTP电子邮件）的数据报。
* **有效载荷长度**。该16比特值作为一个无符号整数，给出了 IPv6数据报中跟在定长的40字节数据报首部后面的字节数量。
* **下一个首部**。该字段标识数据报中的内容（数据字段）需要交付给哪个协议（如TCP或UDP）。该字段使用与IPv4首部中协议字段相同的值。
* **跳限制**。转发数据报的每台路由器将对该字段的内容减1。如果跳限制计数达到0,则该数据报将被丢弃。
* **源地址和目的地址**。
* **数据**。这是IPv6数据报的有效载荷部分。当数据报到达目的地时，该有效载荷就从IP数据报中移出，并交给在下一个首部字段中指定的协议处理。

<img width="428" alt="image" src="https://github.com/user-attachments/assets/f7a0400c-cadf-491f-a55e-9c10c9e8051d">

在IPv4数据报中岀现的几个字段在IPv6数据报中已不复存在：
* **分片/重新组装**。IPv6不允许在中间路由器上进行分片与重新组装。如果路由器收到的IPv6数据报因太大而不能转发到出链路上的话，则路由器只需丢掉该数据报，并向发送方发回一个“分组太大”的ICMP差错报文即可。
* **首部检验和**。因为因特网层中的运输层（如TCP与UDP）和数据链路层（如以太网）协议执行了检验操作，IP设计者大概觉得在网络层中具有该项功能实属多余，所以将其去除。
* **选项**。选项字段不再是标准IP首部的一部分了。但它并没有消失，而是可能出现在IPv6首部中由“下一个首部”指出的位置上。

从IPv4到IPv6的迁移：
<img width="500" alt="image" src="https://github.com/user-attachments/assets/0d40a41a-fe3f-4dae-8445-5d2632210ae4">

## 4.4 通用转发和SDN
我们现在考虑一种更有意义的通用“匹配加动作”范式：   
其中能够对协议栈的多个首部字段进行“匹配”，这些首部字段是与不同层次的不同协议相关联的。   
“动作”能够包括：将分组转发到一个或多个输出端口（就像在基于目的地转发中一样），跨越多个通向服务的离开接口进行负载均衡分组（就像在负载均衡中一样），重写首部值（就像在NAT中一样），有意识地阻挡/丢弃某个分组（就像在防火墙中一样），为进一步处理和动作而向某个特定的服务器发送一个分组（就像在DPI一样），等等。

<img width="600" alt="image" src="https://github.com/user-attachments/assets/a11af8db-a430-4e9d-84e3-7af27a9246c2">

匹配加动作转发表在OpenFlow中称为流表（flow table）,它的每个表项包括:
* 首部字段值的集合，入分组将与之匹配。与基于目的地转发的情况一样，基于硬件匹配在TCAM内存中执行得最为迅速（TCAM内存中可能有上百万条地址表项）。匹配不上流表项的分组将被丢弃或发送到远程控制器做更多处理。
* 计数器集合（当分组与流表项匹配时更新计数器）。这些计数器可以包括已经与该表项匹配的分组数量，以及自从该表项上次更新以来的时间。
* 当分组匹配流表项时所采取的动作集合。这些动作可能将分组转发到给定的输出端口，丢弃该分组、复制该分组和将它们发送到多个输岀端口，和/或重写所选的首部字段

### 4.4.1 匹配
<img width="600" alt="image" src="https://github.com/user-attachments/assets/231d1a27-85a2-41e2-a2bb-b219d1bc1799">

### 4.4.2 动作
最为重要的动作可能是：
* 转发
* 丢弃
* 修改字段

### 4.4.3 匹配加动作操作中的OpenFlow例子
略

## 4.5 小结
在本章中，我们讨论了网络层的数据平面(data plane)功能，即每台路由器的如下功能：决定到达路由器的输入链路之一的分组如何转发到该路由器的输岀链路之一。   

我们从仔细观察路由器的内部操作开始，学习输入和输出端口功能，以及基于目的地的转发、路由器的内部交换机制、分组排队管理等等。我们涉及传统的1P转发（其中转发基于数据报的目的地址进行）和通用转发（其中转发和其他功能可以使用数据报首部中的几个不同的字段值来进行），并且看到了后一种方法的多种用途。我们还详细地学习了IPv4和IPv6协议以及因特网编址，并对此有了更深入、更敏锐和更有趣的发现。

# 网络层：控制平面
## 5.1 概述
<img width="600" alt="image" src="https://github.com/user-attachments/assets/272f41a3-33f8-4573-b676-6875b3481e14">   

<img width="600" alt="image" src="https://github.com/user-attachments/assets/7ccfa16c-75a5-40e0-b165-4aecef537fcc">

## 5.2 路由选择算法
<img width="385" alt="image" src="https://github.com/user-attachments/assets/737f486d-c257-4a95-af79-2ecc3312f5f1">

路由选择算法的一种分类方式是根据该算法是集中式还是分散式来划分：
* **集中式路由选择算法**（centralized routing algorithm）用完整的、全局性的网络知识计算岀从源到目的地之间的最低开销路径。具有全局状态信息的算法常被称作**链路状态**（Link State, LS）算法。
* 在**分散式路由选择算法**（decentralized routing algorithm）中，路由器以迭代、分布式的方式计算出最低开销路径。没有节点拥有关于所有网络链路开销的完整信息。相反，每个节点仅有与其直接相连链路的开销知识即可开始工作。然

第二种广义分类方式是根据算法是静态的还是动态的进行分类：
* 在**静态路由选择算法**（static routing algorithm）中，路由随时间的变化非常缓慢，通常是人工进行调整（如人为手工编辑一条链路开销）。
* **动态路由选择算法**（dynamic routing algorithm）随着网络流量负载或拓扑发生变化而改变路由选择路径。   

路由选择算法的第三种分类方式是根据它是负载敏感的还是负载迟钝的进行划分：
* 在**负载敏感算法**（load-sensitive algorithm）中，链路开销会动态地变化以反映出底层链路的当前拥塞水平。如果当前拥塞的一条链路与高开销相联系，则路由选择算法趋向于绕开该拥塞链路来选择路由。
* 当今的因特网路由选择算法（如RIP、OSPF和BGP）都是**负载迟钝**的（load-insensitive）,因为某条链路的开销不明确地反映其当前（或最近）的拥塞水平。

### 5.2.1 链路状态路由选择算法
我们定义下列记号:
* D(v）: 到算法的本次迭代，从源节点到目的节点。的最低开销路径的开销。
* p(v): 从源到v沿着当前最低开销路径的前一节点(v的邻居）。
* N': 节点子集；如果从源到。的最低开销路径已确知，v在N'中。

LS算法最差情况下复杂性为O(n^2）

<img width="800" alt="image" src="https://github.com/user-attachments/assets/fdc57c58-4226-4dc3-8580-c64420b79e61">   

<img width="739" alt="image" src="https://github.com/user-attachments/assets/47d6f3ef-a2b4-4e15-9f90-5ae922ad1280">

### 5.2.2 距离向量路由选择算法
距离向量（Distance-Vector, DV）算法是一种迭代的、异步的和分布式的算法，而LS算法是一种使用全局信息的算法。说它是分布式的，是因为每个节点都要从一个或多个直接相连邻居接收某些信息，执行计算，然后将其计算结果分发给邻居。说它是迭代的，是因为此过程一直要持续到邻居之间无更多信息要交换为止。说它是异步的，是因为它不要求所有节点相互之间步伐一致地操作。

<img width="501" alt="image" src="https://github.com/user-attachments/assets/3937b815-5c45-4290-a0f3-a1e1fef91d70">

LS与DV路由选择算法的比较:
* 报文复杂性。我们已经看到LS算法要求每个节点都知道网络中每条链路的开销。这就要求要发送0（|N||E|）个报文。而且无论何时一条链路的开销改变时，必须向所有节点发送新的链路开销。DV算法要求在每次迭代时，在两个直接相连邻居之间交换报文。我们已经看到，算法收敛所需时间依赖于许多因素。当链路开销改变时，DV算法仅当在新的链路开销导致与该链路相连节点的最低开销路径发生改变时，才传播已改变的链路开销。
* 收敛速度。我们已经看到LS算法的实现是一个要求O（|N||E|）个报文的O(N^2)算法。DV算法收敛较慢，且在收敛时会遇到路由选择环路。DV算法还会遭遇无穷计数的问题。
* 健壮性。LS算法提供了一定程度的健壮性；

## 5.3 因特网中自治系统内部的路由选择：OSPF
由于规模原因和管理自治的需要，ISP通过将路由器组织进自治系统（Autonomous System, AS）来解决。   

开放最短路优先(OSPF）是一种链路状态协议，OSPF是一个AS内部路由选择协议，它使用洪泛链路状态信息和Dijkstra最低开销路径算法。各条链路开销是由网络管理员配置的。   

## 5.4 ISP之间的路由选择：BGP
在因特网中，所有的AS运行相同的AS间路由选择协议，称为**边界网关协议**（Broder Gateway Protocol, BGP），BGP是一种分布式和异步的协议。  

### 5.4.1 BGP的作用
作为一种AS间的路由选择协议，BGP为每台路由器提供了一种完成以下任务的手段:
1. 从邻居AS获得前缀的可达性信息。
2. 确定到该前缀的“最好的”路由。

### 5.4.2 通告BGP路由信息
对于每个AS，每台路由器要么是一台网关路由器（gateway router）,要么是一台内部路由器（internal router）。   
<img width="500" alt="image" src="https://github.com/user-attachments/assets/30b6576b-addf-48ea-b52b-adb9e288a340">

### 5.4.3 确定最好的路由
1. 热土豆路由选择：即找到最快出所在AS的路径。即它试图减小在它自己AS中的开销，而忽略在其AS之外的端到端开销的其他部分。
2. 路由器选择算法：先看网络管理员有没有设置本地偏好，之后看最短AS-PATH，之后再看热土豆路由选择，最后看BGP标识符。

### 5.4.4 IP任播
如图5-12所示，在IP任播配置阶段，CDN公司为它的多台服务器指派相同的IP地址，并且使用标准的BGP从这些服务器的每台来通告该IP地址。    
<img width="500" alt="image" src="https://github.com/user-attachments/assets/7dd08453-2a3d-4840-8c61-a1329c350cea">

### 5.4.5 路由选择策略
<img width="450" alt="image" src="https://github.com/user-attachments/assets/54ba3b4b-b894-4a5b-abb5-53d868ab6ba7">   

即使X可能知道一条路径（比如说XCY）能到达网络Y，它也将不把该条路径通告给B，由于B不知道X有一条路径到Y，B绝不会经由X转发目的为Y（或C）的流量。这个简单的例子说明了如何使用一条选择的路由通告策略来实现客户/提供商路由选择关系。   

商业运行的ISP们都遵从的一个经验法则是：任何穿越某ISP主干网的流量必须是其源或目的（或两者）位于该ISP的某个客户网络中；不然的话这些流量将会免费搭车通过该ISP的网络。   

为什么会有不同的AS间和AS内部路由选择协议?
* 策略：AS间更看重策略，比如有硬性规定某些流量一定不准经过某AS
* 规模：AS间优先考虑扩展性
* 性能：AS间看重策略，所以性能（比如延时之类）不是第一考虑因素

### 5.4.6 拼装在一起：在因特网中呈现
略

## 5.5 SDN控制平面
SDN体系结构具有4个关键特征：
* 基于流的转发。SDN控制的交换机的分组转发工作，能够基于运输层、网络层或链路层首部中任意数量的首部字段值进行。
* 数据平面与控制平面分离。
* 网络控制功能：位于数据平面交换机外部。
* 可编程的网络。

<img width="450" alt="image" src="https://github.com/user-attachments/assets/8084fa3d-045d-4d61-a9f7-8c814dbb05b0">

### 5.5.1 SDN控制平面：SDN控制器和SDN网络控制应用程序
控制器的功能可大体组织为3个层次：
* 通信层：SDN控制器和受控网络设备之间的通信。
* 网络范围状态管理层。要求控制器具有有关网络的主机、链路、交换机和其他SDN控制设备的最新状态信息
* 对于网络控制应用程序层的接口。该API允许网络控制应用程序在状态管理层之间读/写网络状态和流表。

<img width="450" alt="image" src="https://github.com/user-attachments/assets/f0668da2-ce98-4272-9761-29766ef03bea">

### 5.5.2 OpenFlow 协议
从控制器到受控交换机流动的重要报文有下列这些：
* 配置。设置交换机的配置参数。
* 修改状态。增加/删除或修改交换机流表中的表项，并且设置交换机端口特性。
* 读状态。从交换机的流表和端口收集统计数据和计数器值。
* 发送分组。该报文被控制器用于在受控交换机从特定的端口发送出一个特定的报文。

从受控交换机到控制器流动的重要报文有下列这些：
* 流删除。该报文通知控制器已删除一个流表项，例如由于超时，或作为收到“修改状态”报文的结果。
* 端口状态。交换机用该报文向控制器通知端口状态的变化。
* 分组入。一个分组到达交换机端口，并且不能与任何流表项匹配，那么这个分组将被发送给控制器进行额外处理。匹配的分组也被发送给控制器，作为匹配时所采取的一个动作。“分组入”报文被用于将分组发送给控制器。

### 5.5.3 数据平面和控制平面交互的例子
略

### 5.5.4 SDN的过去与未来
SDN革命正在导致颠覆性地替代专用的整体交换机和路由器（它们同时具有数据平面和控制平面）

## 5.6 ICMP：因特网控制报文协议
由［RFC 792］定义的因特网控制报文协议（ICMP）,被主机和路由器用来彼此沟通网络层的信息。ICMP最典型的用途是差错报告。   

ICMP通常被认为是IP的一部分，但从体系结构上讲它位于IP之上，因为ICMP报文是承载在IP分组中的。这就是说，ICMP报文是作为IP有效载荷承载的，就像TCP与UDP报文段作为IP有效载荷被承载那样。   

<img width="450" alt="image" src="https://github.com/user-attachments/assets/e888f101-f5d5-4a6d-8681-bf4c937c9988">

## 5.7 网络管理和SNMP
### 5.7.1 网络管理框架
<img width="650" alt="image" src="https://github.com/user-attachments/assets/4535c2f8-773b-4d31-92b7-48ffa29c8a86">

### 5.7.2 简单网络管理协议
简单网络管理协议（Simple Network Management Protocol）版本2是一个应用层协议，用于在管理服务器和代表管理服务器执行的代理之间传递网络管理控制和信息报文。

## 5.8 小结
我们现在已经完成了进入网络核心的两章旅程，即开始于第4章的网络层数据平面的学习和本章完成的网络层控制平面的学习。我们知道了控制平面是网络范围的逻辑，它不仅控制从源主机到目的主机沿着端到端路径在路由器之间如何转发数据报，而且控制网络层组件和服务器如何配置和管理。

我们学习了构建控制平面有两大类方法：传统的每路由器控制（其中在每台路由器中运行算法，并且路由器中的路由选择组件与其他路由器中的路由选择组件通信）和软件定义网络 SDN）控制（其中一个逻辑上集中的控制器计算并向每台路由器分发转发表为它们所用）。我们在5.2节中学习了两种基本的路由选择算法，即链路状态和距离矢量，用于计算图中的最小开销路径；这些算法在每路由器控制和SDN控制中都有应用。这些算法是两种广泛部署的因特网路由选择协议OSPF和BGP的基础，我们在5.3节和5.4节中讨论了这两种协议。我们在5.5节中讨论了网络层控制平面的SDN方法，研究了 SDN网络控制应用程序、SDN控制器，以及控制器和SDN控制设备之间通信所使用的OpenFlow协议。在5.6节和5.7节中，我们包括了管理IP网络的某些技术细节：ICMP（互联网控制报文协议）和SNMP（简单网络管理协议）。

# 链路层和局域网
## 6.1 链路层概述
### 6.1.1 链路层提供的服务
* 成帧(framing）。在每个网络层数据报经链路传送之前，几乎所有的链路层协议都要将其用链路层帧封装起来。
* 链路接入。**媒体访问控制**（Medium Access Control, MAC）协议规定了帧在链路上传输的规则。点对点链路和广播链路是不同的
* 可靠交付。当链路层协议提供可靠交付服务时，它保证无差错地经链路层移动每个网络层数据报。通常无线链路会提供可靠交付，其他括光纤、同轴电缆和许多双绞铜线链路之类比较可靠，就通常不提供可靠交付
* 差错检测和纠正。链路层的差错检测通常更复杂，并且用硬件实现。差错纠正类似于差错检测，区别在于接收方不仅能检测帧中出现的比特差错，而且能够准确地确定帧中的差错出现的位置（并因此纠正这些差错）

### 6.1.2 链路层在何处实现
链路层的主体部分是在**网络适配器**（network adapter）中实现的，网络适配器有时也称为网络接口卡（Network Interface Card, NIC）。位于网络适配器核心的是链路层控制器，该控制器通常是一个实现了许多链路层服务（成帧、链路接入、差错检测等）的专用芯片。因此，链路层控制器的许多功能是用硬件实现。但部分链路层是在运行于主机CPU上的软件中实现的。所以，链路层是硬件和软件的结合体，即此处是协议栈中软件与硬件交接的地方   
<img width="400" alt="image" src="https://github.com/user-attachments/assets/9c28ee77-5145-4c99-9730-846406352a96">

## 6.2 差错检测和纠正技术
<img width="550" alt="image" src="https://github.com/user-attachments/assets/4c9d7ab0-4fc4-4b2e-974c-9d206581f185">    

在传输数据中检测差错的3种技术：
* 奇偶校验（它用来描述差错检测和纠正背后隐含的基本思想）、
* 检验和方法（它通常更多地应用于运输层）
* 循环冗余检测（它通常更多地应用在适配器中的链路层）。

### 6.2.1 奇偶校验
在偶校验方案中，发送方只需包含一个附加的比特，选择它的值，使得这d+1比特（初始信息加上一个校验比特）中1的总数是偶数。对于奇校验方案，选择校验比特值使得有奇数个1。   

如果出现了偶数个比特差错，这将导致一个未检出的差错。   

测量已经表明了差错经常以“突发”方式聚集在一起，而不是独立地发生。在突发差错的情况下，使用单比特奇偶校验保护的一帧中未检测出差错的概率能够达到50%   

单比特奇偶校验方案的二维一般化方案：    
<img width="450" alt="image" src="https://github.com/user-attachments/assets/aa194718-8c21-41c1-90b7-3466e930b444">

### 6.2.2 检验和方法
具体参考“UDP检验和”章节   

### 6.2.3 循环冗余检测
现今的计算机网络中广泛应用的差错检测技术基于循环冗余检测（Cyclic Redundancy Check, CRC）编码。算法比较复杂，使用硬件计算。

## 6.3 多路访问链路和协议
了有两种类型的网络链路：
* 点对点链路: (如点对点协议(point-to-point protocol, PPP)和高级数据链路控制(high・level data link control, HDLC)
* 广播链路: 以太网和无线局域网是广播链路层技术的例子

我们能够将任何多路访问协议划分为3种类型之一：
* 信道划分协议（channel partitioning protocol）
* 随机接入协议 random access protocol）
* 轮流协议（taking-turns protocol）

### 6.3.1 信道划分协议
**时分多路复用**（TDM）和**频分多路复用**（FDM）是两种能够用于在所有共享信道节点之间划分广播信道带宽的技术。他们优点是消除了碰撞而且非常公平；缺点是节点被限制于R/N bps的平均速率，节点必须总是等待它在传输序列中的轮次。   

码分多址（Code Division Multiple Access, CDMA）编码类似于TDM中的时隙和FDM中的频率，能分配给多路访问信道的用户。第七章再介绍

### 6.3.2 随机接入协议
1. 时隙ALOHA:
   * 当节点有一个新帧要发送时，它等到下一个时隙开始并在该时隙传输整个帧
   * 如果没有碰撞，该节点成功地传输它的帧，从而不需要考虑重传该帧。
   * 如果有碰撞，该节点在时隙结束之前检测到这次碰撞。该节点以概率p在后续的每个时隙中重传它的帧，直到该帧被无碰撞地传输出去

   时隙ALOHA的确需要在节点中对时隙同步; 时隙ALOHA最大效率为1/e=0.37;

2. ALOHA:
   在纯ALOHA中，当一帧首次到达（即一个网络层数据报在发送节点从网络层传递下来），节点立刻将该帧完整地传输进广播信道。如果一个传输的帧与一个或多个传输经历了碰撞，这个节点将立即（在完全传输完它的碰撞帧之后）以概率p重传该帧。否则，该节点等待一个帧传输时间。在此等待之后，它则以概率p传输该帧，或者以概率1-p在另一个帧时间等待（保持空闲）
   <img width="450" alt="image" src="https://github.com/user-attachments/assets/5b2a15ad-21d1-44ad-9851-392196c5121b">

   不需要同步节点时隙，导致效率为2/e，只有时隙ALOHA的一半。

3. 载波侦听多路访问(CSMA)
   说话之前先听。如果其他人正在说话，等到他们说完话为止。在网络领域中，这被称为**载波侦听**(carrier sensing)。   
   <img width="300" alt="image" src="https://github.com/user-attachments/assets/d6d53303-7970-4347-9ad2-0f81590bdc44">
   
   说的过程不会听，所以一直会把话说下去

5. 具有碰撞检测的载波侦听多路访问（CSMA/CD）
   如果与他人同时开始说话，停止说话。在网络领域中，这被称为**碰撞检测**(collision detection) 。当碰撞发生时，使用**二进制指数后退**（binary exponential backoff）算法确定等待时间。   
   <img width="300" alt="image" src="https://github.com/user-attachments/assets/11bb2101-7963-4d60-8b59-99c7b3f34890">      

6. CSMA/CD 效率
   令dpord表示信号能量在任意两个适配器之间传播所需的最大时间。令dtrans表示传输一个最大长度的以太网帧的时间   
     
   <img width="200" alt="image" src="https://github.com/user-attachments/assets/3eebbd31-d8b8-4b66-9b8b-b94f4d7e5c3a">
   
   从这个公式我们看到, 当dprod接近0时，效率接近1。这和我们的直觉相符，如果传播时延是0,碰撞的节点将立即中止而不会浪费信道。同时, 当dtrans变得很大时，效率也接近于1。这也和直觉相符，因为当一个帧取得了信道时，它将占有信道很长时间；因此信道在大多数时间都会有效地工作

### 6.3.3 轮流协议
轮流协议消除了困扰随机接入协议的碰撞和空时隙，这使得轮流取得高得多的效率。

1. **轮询协议**（polling protocol）：要求这些节点之一要被指定为主节点。主节点以循环的方式轮询（poll）每个节点。特别是，主节点首先向节点1发送一个报文，告诉它（节点1）能够传输的帧的最多数量。在节点1传输了某些帧后，主节点告诉节点2它能够传输的帧的最多数量。（主节点能够通过观察在信道上是否缺乏信号，来决定一个节点何时完成了帧的发送。）上述过程以这种方式继续进行，主节点以循环的方式轮询了每个节点。   
   缺点：   
      1）议引入了轮询时延，尤其是即使只有一个活跃节点，时间到了也要逐个轮询其他节点，询问是否有东西要传输；   
      2）主节点故障问题   

3. **令牌传递协议**（token-passing protocol）：在这种协议中没有主节点。一个称为令牌（token）的小的特殊帧在节点之间以某种固定的次序进行交换。当节点有令牌且有东西要发送的时候就持有令牌，发送一定数量后节点就把令牌传给被人   
   缺点：某节点故障导致令牌没有释放不能传给别人

### 6.3.4 DOCSIS 用于电缆因特网接入的链路层协议
<img width="686" alt="image" src="https://github.com/user-attachments/assets/006becbf-f633-4545-9ca5-84d1d69f9052">

## 6.4 交换局域网
1. **MAC地址**：每个适配器（即网络接口）都有一个固定的MAC地址，MAC地址理论上没有重复的。
2. **地址解析协议**（Address Resolution Protocol, ARP）：ARP有点像DNS, 任务是将IP地址翻译为MAC地址，做法是把ARP查询报文广播到子网，匹配的主机会回答自己的IP对应的MAC地址；
3. **发送数据报到子网以外**：如果跨了子网，目的地MAC应该填的是路由的入MAC地址，如下图:
   <img width="700" alt="image" src="https://github.com/user-attachments/assets/3ce147f2-45e6-4aa7-af9c-4e96e4e2d671">

### 6.4.2 以太网
以太网是到目前为止最流行的有线局域网技术。   
1. 以太网帧结构
   <img width="500" alt="image" src="https://github.com/user-attachments/assets/6649531f-9bdc-44d2-b5aa-ca65b0ff73d4">
   * 数据字段（46 ~ 1500字节）。这个字段承载了IP数据报。
   * 目的地址（6字节）。这个字段包含目的适配器的MAC地址
   * 源地址（6字节）。这个字段包含了传输该帧到局域网上的适配器的MAC地址
   * 类型字段（2字节）。类型字段允许以太网复用多种网络层协议。该字段是为了把一层中的某协议与上一层的某协议结合起来。
   * CRC （4字节）循环冗余检测字段的目的是使得接收适配器检测帧中是否引入了差错
   * 前同步码（8字节）。该前同步码的前7字节的值都是10101010；最后一个字节是10101011。接收适配器只需通过锁定前同步码的前7字节的比特，就能够锁定适配器A的时钟。前同步码的第8个字节的最后两个比特（第一个出现的两个连续的1）警告适配器B, “重要的内容”就要到来了。   

   所有的以太网技术都向网络层提供无连接服务。   
   以太网技术都向网络层提供不可靠服务。CRC检查不通过不会有任何动作

2. 以太网技术   
   <img width="600" alt="image" src="https://github.com/user-attachments/assets/9bb9e451-f30a-421c-bde9-6da363baba5f">

   在总线拓扑和基于集线器的星形拓扑技术时代，以太网很显然是一种广播链路(如6.3节所定义)，其中多个节点同时传输时会出现帧碰撞。为了处理这些碰撞，以太网标准包括CSMA/CD协议，该协议对于跨越一个小的地理半径的有线广播局域网特别有效。但是对于今天广为使用的以太网是基于交换机的星形拓扑，采用的是存储转发分组交换，是否还真正需要一种以太网MAC协议呢？如我们很快所见，交换机协调其传输，在任何时候决不会向相同的接口转发超过一个帧。此外，现代交换机是全双工的，这使得一台交换机和一个节点能够在同时向对方发送帧而没有干扰。换句话说，在基于交换机的以太局域网中，不会有碰撞，因此没有必要使用MAC协议了（MAC协议参考6.1.1）!

### 6.4.3 链路层交换机
1. 交换机转发和过滤
   **过滤**（filtering）是决定一个帧应该转发到某个接口还是应当将其丢弃的交换机功能。**转发**（forwarding）是决定一个帧应该被导向哪个接口，并把该帧移动到那些接口的交换机功能。交换机的过滤和转发借助于**交换机表**（switch table）完成。
   <img width="600" alt="image" src="https://github.com/user-attachments/assets/eac3756b-9b4d-43d9-9511-15c2e0149a41">

   假定目的地址为DD-DD-DD-DD-DD-DD的帧从交换机接口x到达：
   * 如果没有对于目的地址的表项，交换机广播该帧
   * 表中有一个表项将DD-DD-DD-DD-DD-DD与接口x联系起来。如果一个数据从该MAC到达x端口，那么无须将该帧转发到任何其他接口，交换机通过丢弃该帧执行过滤功能即可
   * 否则就转发到该端口

2. 自学习   
   交换表是自学习的：   
   * 交换机表初始为空
   * 对于在每个接口接收到的每个入帧，该交换机在其表中存储MAC地址和端口，还有时间
   * 超过一定时间后将老旧记录删除
  
4. 链路层交换机的性质
   * 消除碰撞，效率高
   * 异质的链路。能够将不同速率的链路互通
   * 管理。流量隔离，断线隔离
  
5. 交换机和路由器比较   
   交换机：优点：即插即用；工作在二层效率好；缺点：维护ARP表的成本；对广播风暴没有保护   
   路由：优点：分组通常也不会通过路由器循环。允许以丰富的拓扑结构构建，数据可以选择更优路径；缺点：非即插即用需要配置ip; 工作在第三层效率没有交换机高
           
   <img width="400" alt="image" src="https://github.com/user-attachments/assets/4e6a626e-9bbe-487f-b97e-480db83b18ed">

### 6.4.4 虚拟局域网
持虚拟局域网（Virtula Local Network, VLAN）。支持VLAN的交换机允许经一个单一的物理局域网基础设施定义多个虚拟局域网。

## 6.5 链路虚拟化：网络作为链路层
多协议标签交换（Multiprotocol Label Switching, MPLS）：我们关于MPLS的讨论重点基于这样的事实，MPLS基于标签执行交换, 而不必考虑分组的IP地址。

## 6.6 数据中心网络
<img width="600" alt="image" src="https://github.com/user-attachments/assets/f41752a5-c882-44b8-833c-13a860b12b49">   

1. 负载均衡：负载均衡器不仅平衡主机间的工作负载，而且还提供类似NAT的功能
2. 等级体系结构：主要是为了解决数据中心规模过大的问题；分等级后可能会带来跨等级的性能问题。
3. 数据中心网络的发展趋势
   * 全连接拓扑（fully connected topology）来替代交换机和路由器的等级结构能克服跨等级带来的性能问题   
     <img width="600" alt="image" src="https://github.com/user-attachments/assets/0ee2efba-4ac8-4217-8851-b2dfe01a5e37">
   * 用基于船运集装箱的模块化数据中心（Modular Data Center, MDC）
   * 大型云提供商正在其数据中心越来越多地建造或定制几乎所有东西，包括网络适配器、交换机路由器、TOR 软件和网络协议


## 6.7 回顾: Web页面请求的历程
<img width="700" alt="image" src="https://github.com/user-attachments/assets/7672b327-46e4-49e7-8c2e-00a7f6a1ece4">   

### 6.7.1 准备：DHCP. UDP IP和以太网
当Bob首先将其便携机与网络连接时，没有IP地址他就不能做任何事情（例如下载一个Web网页）。所以，Bob的便携机所采取的一个网络相关的动作是运行DHCP协议,以从本地DHCP服务器获得一个IP地址以及其他信息。
1. Bob便携机上的操作系统生成一个DHCP请求报文（4.3.3节），并将这个报文放入具有目的端口 67 （DHCP服务器）和源端口 68 （DHCP客户）的UDP报文段（3.3节）该UDP报文段则被放置在一个具有广播IP目的地址(255.255.255.255）和源IP地址0.0.0.0的IP数据报中（4.3.1节），因为Bob的便携机还没有一个IP地址。
2. 包含DHCP请求报文的IP数据报则被放置在以太网帧中（6.4.2节）。该以太网帧具有目的MAC地址FF:FF:FF:FF:FF:FF,使该帧将广播到与交换机连接的所有设备（如果顺利的话也包括DHCP服务器）；该帧的源MAC地址是Boh便携机的MAC地址00:16:D3:23:68:8A
3. 包含DHCP请求的广播以太网帧是第一个由Bob便携机发送到以太网交换机的帧。该交换机在所有的出端口广播入帧，包括连接到路由器的端口。
4. 路由器在它的具有MAC地址OO 22 6B 45 1F的接口接收到该广播以太网帧，该帧中包含DHCP请求，并且从该以太网帧中抽取出IP数据报。该数据报的广播IP目的地址指示了这个IP数据报应当由在该节点的高层协议处理，因此该数据报的载荷（一个UDP报文段）被分解 3.2节）向上到达UDP, DHCP请求报文从此UDP报文段中抽取出来。此时DHCP服务器有了 DHCP请求报文。
5. 我们假设运行在路由器中的DHCP服务器能够以CIDR （4.3.3节）块68.85.2.0/24分配IP地址。所以本例中，在学校内使用的所有IP地址都在Comcast的地址块中。我们假设DHCP服务器分配地址68. 85. 2. 101给Bob的便携机。DHCP服务器生成包含这个IP地址以及DNS服务器的1P地址（68.87.71.226）、默认网关路由器的IP地址(68.85.2.1）和子网块(68.85.2.0/24）（等价为“网络掩码”）的一个DHCP ACK报文（4.3.3节）。该DHCP报文被放入一个UDP报文段中，UDP报文段被放入一个IP数据报中，IP数据报再被放入一个以太网帧中。这个以太网帧的源MAC地址是路由器连到归属网络时接口的MAC地址 OO 22 6B 45 1F 1B）,目的MAC地址是Bob便携机的MAC地址（00： 16： D3 23 68 8A）O
6. 包含DHCP ACK的以太网帧由路由器发送给交换机。因为交换机是自学习的（6.4.3节），并且先前从Bob便携机收到（包含DHCP请求的）以太网帧，所以该交换机知道寻址到00： 16 D3 23 68 8A的帧仅从通向Bob便携机的输岀端口转发。
7. Bob便携机接收到包含DHCP ACK的以太网帧，从该以太网帧中抽取IP数据报,从IP数据报中抽取UDP报文段，从UDP报文段抽取DHCP ACK报文。Bob的DHCP客户则记录下它的IP地址和它的DNS服务器的IP地址。它还在其IP转发表中安装默认网关的地址 4.1节）。Bob便携机将向该默认网关发送目的地址为其子网68. 85. 2. 0/24以外的所有数据报。此时，Bob便携机已经初始化好它的网络组件，并准备开始处理Web网页获取。（注意到在第4章给出的四个步骤中仅有最后两个DHCP步骤是实际必要的。）

### 6.7.2 仍在准备：DNS和ARP
当Bob将www. google, com的URL键入其Web浏览器时，他开启了一长串事件，这将导致谷歌主页最终显示在其Web浏览器上。Bob的Web浏览器通过生成一个TCP套接字（2. 7节）开始了该过程，套接字用于向www. google, com发送HTTP请求 2.2节）。为了生成该套接字，Bob便携机将需要知道www. google, com的IP地址。我们在2. 4节中学过,使用DNS协议提供这种名字到IP地址的转换服务。

8. Bob便携机上的操作系统因此生成一个DNS查询报文 2.4.3节），将字符串www.google.com放入DNS报文的问题段中。该DNS报文则放置在一个具有53号（DNS服务器）目的端口的UDP报文段中。该UDP报文段则被放入具有IP目的地址68. 87. 71. 226 （在第5步中DHCP ACK返回的DNS服务器地址）和源IP地址68. 85. 2. 101的IP数据报中。
9. Bob便携机则将包含DNS请求报文的数据报放入一个以太网帧中。该帧将发送（在链路层寻址）到Bob学校网络中的网关路由器。然而，即使Bob便携机经过上述第5步中的DHCP ACK报文知道了学校网关路由器的IP地址（6& 85.2. 1）,但仍不知道该网关路由器的MAC地址。为了获得该网关路由器的MAC地址，Bob便携机将需要使用ARP协议（6. 4. 1节）°
10. Bob便携机生成一个具有目的IP地址68. 85. 2. 1 （默认网关）的ARP查询报文,将该ARP报文放置在一个具有广播目的地址 FF FF FF FF FF FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧交付给所有连接的设备，包括网关路由器。
11. 网关路由器在通往学校网络的接口上接收到包含该ARP查询报文的帧，发现在ARP报文中目标IP地址68. 85. 2. 1匹配其接口的IP地址。网关路由器因此准备一个ARPI答，指示它的MAC地址OO 22 6B 45 1F 1B对应IP地址68. 85. 2. 1 o它将ARP回答放在一个以太网帧中，其目的地址为00 16 D3 23 68 8A （Bob便携机），并向交换机发送该帧，再由交换机将帧交付给Bob便携机。
12. Bob便携机接收包含ARP回答报文的帧，并从ARP回答报文中抽取网关路由器的 MAC 地址 00 22 6B 45 IF 1B）
13. Boh便携机现在（最终！）能够使包含DNS查询的以太网帧寻址到网关路由器的MAC地址。注意到在该帧中的IP数据报具有IP目的地址68. 87.71.226 （ DNS服务器）,而该帧具有目的地址OO 22 6B 45 1F 1B （网关路由器）。Bob便携机向交换机发送该帧,交换机将该帧交付给网关路由器。

### 6.7.3 仍在准备：域内路由选择到DNS服务器
14. 网关路由器接收该帧并抽取包含DNS查询的IP数据报。路由器查找该数据报的目的地址（68. 87.71.226）,并根据其转发表决定该数据报应当发送到图6・32的Comcast网络中最左边的路由器。IP数据报放置在链路层帧中，该链路适合将学校路由器连接到最左边Comcast路由器，并且该帧经这条链路发送。
15. 在Comcast网络中最左边的路由器接收到该帧，抽取IP数据报，检查该数据报的目的地址（68. 87. 71.226）,并根据其转发表确定出接口，经过该接口朝着DNS服务器转发数据报，而转发表已根据Comcast的域内协议（如RIP OSPF或IS IS, 5.3节）以及因特网的域间协议BGP （5.4节）所填写。
16. 最终包含DNS查询的IP数据报到达了 DNS服务器。DNS服务器抽取出DNS查询报文，在它的DNS数据库中查找名字www. google, com （ 2. 4节），找到包含对应WWW. google, com的IP地址 64.233.169.105）的DNS源记录° （假设它当前缓存在DNS服务器中。）前面讲过这种缓存数据源于google, com的权威DNS服务器 2.4.2节）。该DNS服务器形成了一个包含这种主机名到IP地址映射的DNS回答报文，将该DNS回答报文放入UDP报文段中，该报文段放入寻址到Bob便携机（68. 85. 2. 101）的IP数据报中。该数据报将通过Comcast网络反向转发到学校的路由器，并从这里经过以太网交换机到Bob便携机
17. Bob便携机从DNS报文抽取出服务器www. google, com的IP地址。最终，在大量工作后，Bob便携机此时准备接触www. google, com服务器！

### 6.7.4 Web客户-服务器交互:TCP和HTTP
18. 既然Bob便携机有了 www. google, com的IP地址，它能够生成TCP套接字 2. 7节），该套接字将用于向www. google, com发送HTTP GET报文 2. 2. 3节 。当Bob生成TCP套接字时，在Bob便携机中的TCP必须首先与www. google, com中的TCP执行三次握手（3. 5.6节）。Bob便携机因此首先生成一个具有目的端口 80 （针对HTTP的）的TCP SYN报文段，将该TCP报文段放置在具有目的IP地址64. 233. 169. 105 （www. google, com）的IP数据报中，将该数据报放置在MAC地址为OO 22 6B 45 1F 1B （网关路由器）的帧中,并向交换机发送该帧。
19. 在学校网络、Comcast网络和谷歌网络中的路由器朝着www. google, com转发包含TCP SYN的数据报，使用每台路由器中的转发表，如前面步骤14〜16那样。前面讲过支配分组经Comcast和谷歌网络之间域间链路转发的路由器转发表项，是由BGP协议决定的（第5章）。 ；
20. 最终，包含TCP SYN的数据报到达www.googole.com 从数据报抽取出TCP SYN报文并分解到与端口 80相联系的欢迎套接字。对于谷歌HTTP服务器和Bob便携机之间的TCP连接生成一个连接套接字 2.7节）。产生一个TCP SYNACK （3.5.6节）报文段,将其放入向Bob便携机寻址的一个数据报中，最后放入链路层帧中，该链路适合将WWW. google, com连接到其第一跳路由器。
21. 包含TCP SYNACK报文段的数据报通过谷歌、Comcast和学校网络，最终到达Bob便携机的以太网卡。数据报在操作系统中分解到步骤18生成的TCP套接字，从而进入连接状态。
22. 借助于Bob便携机上的套接字，现在（终于！）准备向www. google, com发送字节T, Bob的浏览器生成包含要获取的URL的HTTP GET报文 2.2.3节）。HTTP GET报文则写入套接字，其中GET报文成为一个TCP报文段的载荷。该TCP报文段放置进一个数据报中，并交付到WWW. google, com,如前面步骤18-20所述。
23. 在www. google, com的HTTP服务器从TCP套接字读取HTTP GET报文，生成一个HTTP响应报文 2. 2节），将请求的Web页内容放入HTTP响应体中，并将报文发送进TCP套接字中。
24. 包含HTTP回答报文的数据报通过谷歌、Comcast和学校网络转发，到达Bob便携机。Bob的Web浏览器程序从套接字读取HTTP响应，从HTTP响应体中抽取Web网页的html,并最终（终于！）显示了 Web网页

## 6.8 小结
在这一章中，我们学习了链路层，包括它的服务、支撑它操作的原则和许多重要的特定协议，它们使用这些原则实现了链路层服务。   

我们看到链路层的基本服务是将网络层的数据报从一个节点（主机、交换机、路由器，WiFi接入点）移动到一个相邻的节点。我们看到，在通过链路向相邻节点传输之前,所有链路层协议都是通过将网络层数据报封装在链路层帧中来操作的。然而，除了这个共同的成帧功能之外，我们知道了不同的链路层协议提供截然不同的链路接入、交付和传输服务。造成这些差异的部分原因是链路层协议必须工作在很多种链路类型上。一个简单的点对点链路具有单个发送方和接收方，并通过单一 “线路”通信。一个多路访问链路在许多发送方和接收方之间共享；因此，对多路访问信道的链路层协议有一个协调链路接入的协议（它的多路访问协议）。在MPLS的情况下，连接两个相邻节点（例如，在IP意义上的两台相邻的IP路由器，它们是到某个目的地的下一跳IP路由器）的“链路”，其本身可能实际上就是一个网络。从某种意义来说，将一个网络视为一条“链路”的想法没有什么可奇怪的。例如，连接家庭调制解调器/计算机到远端调制解调器/路由器的一条电话链路，实际上是一条穿过精密而复杂的电话网络的路径   

在链路层通信所依据的原理中，我们研究了差错检测和纠正技术、多路访问协议、链路层寻址、虚拟化 VLAN）以及扩展的交换局域网和数据中心网络的构造方法。今天对链路层的许多关注在于这些交换网络。在差错检测/纠正场景中，为了对帧通过链路传输时可能发生的比特翻转进行检测并在某些情况下进行纠正，我们研究了在帧的首部增加附加比特的方法。我们讨论了简单的奇偶校验和检验和方案，以及更健壮的循环冗余检测。然后我们转向多路访问协议主题。我们确定和学习了协调访问广播信道的3大类方法:信道划分方法 TDM FDM） 随机接入方法 ALOHA协议和CSMA协议）和轮流方法（轮询和令牌传递）。我们学习了电缆接入网，发现它使用了多种这些多路访问方法。我们看到让多个节点共享单个广播信道的结果，是需要在链路层提供节点地址。我们知道物理地址和网络层地址是非常不同的，而且在因特网场景中，一个专门的协议 ARP,即地址解析协议）用于在这两种寻址形式之间进行转换，并且详细学习了极为成功的以太网协议。然后我们研究了共享一个广播信道的节点是怎样形成一个局域网的，以及多个局域网怎样能够互联形成一个更大的局域网，即互联这些本地节点完全不需要网络层路由选择的干预。我们也知道了多个虚拟局域网是怎样能够产生一个单一的物理局域网体系结构的    

通过关注当MPLS网络互联IP路由器时是如何提供链路层服务的和展望今天用于大型数据中心的网络设计，我们结束了链路层的学习。通过识别在获取一个简单的Web网页时所需要的许多协议，我们完成了本章

# 无线网络和移动网络
## 7.1 概述
<img width="488" alt="image" src="https://github.com/user-attachments/assets/36b65b34-c488-4e9a-8dff-d36efb78d37c">      


<img width="488" alt="image" src="https://github.com/user-attachments/assets/3c1942a5-7ed7-4a5c-8970-3173130aca15">    

无线网络类型进行分类：   
* 单跳，基于基础设施。这些网络具有与较大的有线网络（如因特网）连接的基站。此外，该基站与无线主机之间的所有通信都经过一个无线跳。你在教室、咖啡屋或图书馆中所使用的802. 11网络，以及我们将很快学习的4GLTE数据网络都属于这种类型。我们日常的绝大部分时间是在与单跳、基于基础设施的无线网络打交道
* 单跳，无基础设施。在这些网络中，不存在与无线网络相连的基站。然而，如我们将要见到的那样，在这种单跳网络中的一个节点可以协调其他节点的传输。蓝牙网络（该网络连接诸如键盘、扬声器和戴在头上的耳机等小型无线设备，我们将在7.3.6节中学习）和具有自组织模式的802.11网络是单跳、无基础设施的网络。
* 多跳，基于基础设施。在这些网络中，一个基站表现为以有线方式与较大网络相连。然而，某种无线节点为了经该基站通信，可能不得不通过其他无线节点中继它们的通信。某些无线传感网络和所谓无线网状网络（wireless mesh network）就属于这种类型。
* 多跳，无基础设施。一类网络被称为移动自组织网络（mobile ad hoc network, MANET）。如果该移动节点是车载的，该网络是车载自组织网络（vehicular ad hoc network,VANET）。

## 7.2 无线链路和网络特征
有线链路和无线链路间的许多重要区别：
* 递减的信号强度。
* 来自其他源的干扰。
* 多径传播。当电磁波的一部分受物体和地面反射，在发送方和接收方之间走了不同长度的路径，则会出现**多径传播**（multipath propagation）。

**信噪比**（Signal-to-Noise Ratio, SNR）是所收到的信号（如被传输的信息）和噪声强度的相对测量。SNR越高越好。   
**比特差错率**BER，大致说来，BER是在接收方收到的有错传输比特的概率    

<img width="350" alt="image" src="https://github.com/user-attachments/assets/23896da8-8c30-4733-bbd2-7980ef4f5af6">    

* 对于给定的调制方案，SNR越高，BER越低。由于发送方通过增加它的传输功率就能够增加SNR,因此发送方能够通过增加它的传输功率来降低接收到差错帧的概率。但是这有上限，提升到一定程度作用就不大了，而且还容易产生对别人的干扰
* 对于给定的SNR,具有较高比特传输率的调制技术 （无论差错与否）将具有较高的BER。就是传得越快越容易错
* 物理层调制技术的动态选择能用于适配对信道条件的调制技术。

> 无线链路中虽然也是广播，但是因为信号问题，导致不是所有节点时常不都能听到别人的信号，导致在有线网路中的“聆听”方式不好使

CDMA   
码分多址(Code Division Multiple Access, CDMA)属于信道划分协议族。在CDMA协议中，要发送的每个比特都通过乘以一个信号(编码)的比特来进行编码，这个信号的变化速率(通常称为码片速率，chipping rate) 比初始数据比特序列的变化速率快得多。    

类比，一个CDMA协议类似于让聚会客人使用多种语言来谈论；在这种情况下，人们实际上非常善于锁定他们能听懂的语言的谈话，而过滤了其余的谈话。我们这里看到CDMA是一个划分协议，因为它划分编码空间(与时间或频
率相对)，并且给每个节点分配一段专用的代码空间。   

<img width="550" alt="image" src="https://github.com/user-attachments/assets/52209bd0-76bb-4946-a71a-b28b58860b89">  


## 7.3 WiFi 802.11无线LAN
<img width="300" alt="image" src="https://github.com/user-attachments/assets/154efb31-3c0d-42c8-b747-1f4844ebdd9f">  

### 7.3.1 802.11体系结构
802.11体系结构的基本构件模块是**基本服务集**（Basic Service Set, BSS）。一个BSS包含一个或多个无线站点和一个在802.11术语中称为**接入点**（Access Point, AP）的中央基站（base station）。   

<img width="550" alt="image" src="https://github.com/user-attachments/assets/a5e94994-db68-4db3-9e52-83667d50e09d">     

信道与关联   
802.11定义了11个部分重叠的信道。当且仅当两个信道由4个或更多信道隔开时它们才无重叠。特别是信道1、6和11的集合是唯一的3个非重叠信道的集合。

<img width="550" alt="image" src="https://github.com/user-attachments/assets/055e5ca8-7ed4-4c31-8b26-943eddd7f0e0"> 

### 7.3.2 802.11 MAC协议
802.11无线LAN选择了一种随机访问协议。这个随机访问协议称作**带碰撞避免的CSMA**（ CSMA with collision avoidance）,或简称为CSMA/CAO与以太网的CSMA/CD相似，CSMA/CA中的“CSMA”代表“载波侦听多路访问”，意味着每个站点在传输之前侦听信道，并且一旦侦听到该信道忙则抑制传输。尽管以太网
和802. 11都使用载波侦听随机接入，但这两种MAC协议有重要的区别。首先，802.11使用碰撞避免而非碰撞检测。其次，由于无线信道相对较高的误比特率，802.11 （不同于以太网）使用链路层确认/重传（ARQ）方案。   

802.11 MAC协议并未实现碰撞检测。这主要由两个重要的原因所致:
* 检测碰撞的能力要求站点具有同时发送（站点自己的信号）和接收（检测其他站点是否也在发送）的能力。因为在802. 11适配器上，接收信号的强度通常远远小于发送信号的强度，制造具有检测碰撞能力的硬件代价较大。
* 更重要的是，即使适配器可以同时发送和监听信号（并且假设它一旦侦听到信道忙就放弃发送），适配器也会由于隐藏终端问题和衰减问题而无法检测到所有的碰撞。

802.11的**链路层确认**(link-layeracknowledgment）方案: 目的站点收到一个通过CRC校验的帧后，它等待一个被称作**短帧间间隔**（Short Inter-Frame Spacing, SIFS）的一小段时间，然后发回一个确认帧。如果发送站点在给定的时间内未收到确认帧，它假定出现了错误并重传该帧，使用CSMA/CA协议访问该信道。如果在若干固定次重传后仍未收到确认，发送站点将放弃发送并**丢弃**该帧。   

<img width="350" alt="image" src="https://github.com/user-attachments/assets/8291ceeb-b1d9-4dac-ab00-6c088e094fe3">      


**CSMA/CA协议**：
1. 如果某站点最初监听到信道空闲，它将在一个被称作**分布式帧间间隔**（Distributed Inter-Frame Space, DIFS）的短时间段后发送该帧
2. 否则，该站点选取一个随机回退值（如我们在6.3.2节中遇到的那样）并且在侦听信道空闲时递减该值。当侦听到信道忙时，计数值保持不变
3. 当计数值减为0时（注意到这只可能发生在信道被侦听为空闲时），该站点发送整个数据帧并等待确认。
4. 如果收到确认，发送站点知道它的帧已被目的站正确接收了。如果该站点要发送另一帧，它将从第二步开始CSMA/CA协议。如果未收到确认，发送站点将重新进入第二步中的回退阶段，并从一个更大的范围内选取随机值。

802.11的目标是无论如何尽可能避免碰撞。   

**处理隐藏终端：RTS和CTS**  
IEEE 802.11协议允许站点使用一个**短请求发送**(Request to Send, RTS)控制帧和一个**短允许发送**(Clear to Send, CTS)控制帧来**预约**对信道的访问。   

<img width="450" alt="image" src="https://github.com/user-attachments/assets/d6c9c4d1-6e8b-4ead-a3ae-f0558b0c60a1">  

### 7.3.3 IEEE 802.11 帧
![image](https://github.com/user-attachments/assets/a1ab3cb3-b8fd-44b5-b25d-2a5224c8dd1c)    

1. 有效载荷与CRC字段：通常是由一个IP数据报或者ARP分组组成；通常小于1500字节；CRC在无线网络中显得更加重要
2. 地址字段：
   * 当AP在自组织模式中互相转发时使用第四个地址
   * 地址2是传输该帧的站点的MAC地址。
   * 地址1是要接收该帧的无线站点的MAC地址
   * 地址3在BSS和有线局域网互联中起着关键作用
   > 感觉有了地址3，AP的设计能简单很多，不需要链路转发表了
3. 序号、持续期和帧控制字段
   * 序号与TCP的序号作用类似
   * 持续期与协议允许传输节点预约信道一段时间有关
   * 帧控制字段包括许多子字段
        * 类型和子类型字段用于区分关联、RTS CTS ACK和数据帧。
        * To和From字段用于定义不同地址字段的含义。（这些含义随着使用自组织模式或者基础设施模式而改变，而且在使用基础设施模式时，也随着是无线站点还是AP在发送帧而变化。）
        * WEP字段指示了是否使用加密

### 7.3.4 在相同的IP子网中的移动性
当这些BSS属于同一子网时，移动性可以用一种相对直接的方式解决。当站点在不同子网间移动时，就需要更为复杂的移动性管理协议了。     

![image](https://github.com/user-attachments/assets/2bea62f2-19bf-42cc-ba15-75ad3f1317ee)     

如何解决H1从AP1移动到AP2后，交换机的转发表已经把数据导向AP1的问题? 一种解决方法（真有点不规范）是在新的关联形成后，让AP2以H1的源地址向交换机发送一以太网广播帧。当交换机收到该帧后，更新其转发表，使得H1可以通过AP2到达。

### 7.3.5 802.11中的高级特色
1. 802.11速率适应: 某些802.11实现具有一种速率自适应能力，该能力自适应地根据当前和近期信道特点来选择下面的物理层调制技术。
2. 功率管理

### 7.3.6 个人域网络：蓝牙和ZigBee
1. 蓝牙:
   * IEEE 802.15.1网络以低功率和低成本在小范围内运行
   * 能够提供高达4Mbps的数据率
   * 是自组织网络：不需要网络基础设施（如一个接入点）来互连设备
   * 802.15.1设备必须自己进行组织。802.15.1设备首先组织成一个多达8个活动设备的**皮可网**（piconet）,如图7・16所示。这些设备之一被指定为主设备,其余充当从设备。主节点真正控制皮可网，即它的时钟确定了皮可网中的时间，它可以在每个奇数时隙中发送，而从设备仅当主设备在前一时隙与其通信后才可以发送，并且只能发送给主设备。除了从设备，网络中还可以有多达255个的寄放（parked）设备。这些设备仅当其状态被主节点从寄放转换为活动之后才可以进行通信。
  
2. ZigBee：
   * 比蓝牙更低功率
   * 适合比如家庭温度和光线传感器、安全设备和墙上安装的开关
   * 机制和蓝牙皮可网有点像

## 7.4 蜂窝因特网接入
### 7.4.1 蜂窝网体系结构概述
1G已经不存在；2G主要为语音设计；3G,4G向数据方向发展

### 7.4.2 3G蜂窝数据网：将因特网扩展到蜂窝用户
略

### 7.4.3 走向 4G LTE
1. 4G系统体系结构：一个全IP核心网   
   ![image](https://github.com/user-attachments/assets/05f2a2e8-86d6-4050-b767-688d52fbc991)
   * 一种统一的、全IP网络体系结构。4G体系结构是“全IP的”，即语音和数据都承载在IP数据报中，来自/去往无线设备(用户设备，4G的术语为UE）,到分组网关 P GW） ——该P GW将4G边缘网络连接到网络的其他部分。
   * 4G数据平面与4G控制平面的清晰分离。
   * 无线电接入网与全IP核心网之间的清晰分离。
   * eNodeB是2G基站和3G无线电网络控制器（又称为节点B）的逻辑后代，并且此时还起着关键作用。
   * 分组数据网络网关（Packet Data Network Gateway, P-GW）给UE分配IP地址，并且保证QoS实施。
   * 服务网关（S-GW）是数据平面移动性锚点，即所有UE流量将通过S GW传递。
   * 移动性管理实体 (Mobility Management Entity, MME) 代表位于它所控制单元中的UE,执行连接和移动性管理。
   * 归属用户服务（Home Subscriber Server, HSS）包含了包括漫游接入能力、服务质量配置文件和鉴别信息的UE信息。
2. LTE无线电接入网：LTE在下行信道采用频分复用和时分复用结合的方法，称之为正交频分复用（Orthogonal Frequency Division Multiplexing, OFDM）技术

## 7.5 移动管理: 原理
后续补充

## 7.6 移动IP
后续补充

## 7.7 管理蜂窝网中的移动性
后续补充

## 7.8 无线和移动性：对高层协议的影响
后续补充

## 7.9 小结
本章以对无线网络和移动网络的介绍开始，描述了由这种网络中通信链路的无线特性所引发的挑战和由这些无线链路带来的移动性之间的重要区别。这使我们能够更好地区分、识别和掌握每个领域中的关键概念。我们首先关注无线通信，在7. 2节中考虑了无线链路的特征。在7.3节和7.4节中，我们研究了 IEEE 802. 11 (WiFi)无线LAN标准、两个IEEE 802. 15个人域网络(蓝牙和ZigBee),以及3G和4G蜂窝因特网接入。然后我们将注意力转向移动性问题。在7. 5节中我们区分了多种形式的移动性，不同的移动性面临不同的挑战，并且看到了不同的解决方案。我们考虑了移动节点的定位和路由选择问题,以及对那些动态地从一个网络接入点移到另一个网络接入点的移动用户的切换问题。在7. 6节和7. 7节中，我们分别考察了这些问题在移动IP标准和GSM中是如何处理的。最后，我们在7. 8节中考虑了无线链路和移动性对运输层协议和网络应用的影响。

# 计算机网络中的安全
## 8.1 什么是网络安全
* **机密性**(confidentiality) 仅有发送方和希望的接收方能够理解传输报文的内容。
* **报文完整性**(message integrity)
* **端点鉴别**(end-point authentication)
* **运行安全性**(operational security)。防火墙和入侵检测系统等运行设备正被用于反制对机构网络的攻击。   

安全攻击方式有：窃听通信内容（可能窃取口令和数据），假冒另一个实体, “劫持” 一个正在进行的会话，通过使系统资源过载拒绝合法网络用户的服务请求等等。   

## 8.2 密码学的原则
### 8.2.1 对称密钥密码体制
**凯撒密码**(Caesar cipher)：凯撒密码用于英语文本时，将明文报文中的每个字母用字母表中该字母后第k个字母进行替换。例如，如果k=3,则明文中的字母变成密文中的字母“d” 明文中的字母“b”变成密文中的字母“e”。凯撒密码问题是太弱，秘钥值只有25个，所以很容易就破解。   

**单码代替密码**(monoalphabetic cipher)，变化很多，有10的26次方中字母配对，但是使用概率分析，会容易受唯密文攻击      
![image](https://github.com/user-attachments/assets/bb242bf3-dbac-4032-a525-e217daba68c4)

* 唯密文攻击。有些情况下，入侵者只能得到截取的密文，也不了解明文报文的内容。统计分析有助于对加密方案的唯密文攻击。
* 已知明文攻击。如果Trudy以某种方式确信在密文报文中会出现"bob”和"alicen ,她就可以确定字母a l i c e b和。的（明文，密文）匹配关系。
* 选择明文攻击。如果 Trudy 能让 Alice 发送报文"The quick brown fox jumps over the lazy dog” 则Trudy就能够完全破解Alice和Bob所使用的加密方案。

**多码代替密码**（polyalphabetic encryption）,这种技术是对单码代替密码的改进。   
![image](https://github.com/user-attachments/assets/f4d410cd-9849-4aec-bd2d-e71be9390f6d)     

明文报文"bob, i love you. 加密后成为“ghu, n etox dhz.”。注意到明文报文中的第一个“b”用C1加密为“g” 第二个“b" 用C2加密为“u” 在这个例子中，加密和解密“密钥” 是两个凯撒密码密钥(k=5和k=19）和C1, C2, C2, C1, C2的次序模式的知识。

**块密码**    
在块密码中，要加密的报文被处理为A比特的块。例如，如果A=64,则报文被划分为64比特的块，每块被独立加密。     
![image](https://github.com/user-attachments/assets/3bb3ce7c-6eb8-4c54-9ac9-616e03bc4fe2)    

如上图，假设块密码有3位，即k=3，则共有2^3=8种可能的输入。这8种输入能够排列为8!=40320种不同方式。这是k=3的情况，如果k=64也会是个天文数字。   
   
如上所述，对于k=64和给定的映射，要求将要求Alice和Bob维护一张具有2^64个输入值的表，这是一个难以实现的任务。所以用函数模拟随机排列表：   

![image](https://github.com/user-attachments/assets/2880ee8f-dac9-48c9-9bb8-115dbd3a61de)      

流行的块密码，包括**DES**(Data Encryption Standard,数据加密标准)、**3DES**和**AES**(Advanced Encryption Standard,高级加密标准)。DES已经证明不太安全，现在都使用AES: 如果用1秒破解56比特DES的计算机(就是说，每秒尝试所有2^56个密钥)来破解一个128比特的AES密钥，要用大约149万亿年的时间才有可能成功。   

**密码块链接**   
只使用块密码有个问题：例如，两个或更多块中的明文可能是“HTTP/1.1”。对于这些相同的块，块密码当然将产生相同的密文。当攻击者看到相同的密文块时，它可能潜在地猜出其明文，并且通过识别相同的密文块和利用支撑协议结构的知识，甚至能够解密整个报文。   

为了解决这个问题，可以在密文中混合某些随机性，使得相同的明文块产生不同的密文块：   
发送方发送c(1)、 r(1)、c(2)、r(2)、c(3)和r(3), 其中c(i)是加密块，r(i)是随机相同位数的比特，明文传输即可。这样做的问题是流量翻倍，因为引入了r(i)。解决方法是称为**密码块链接**(Cipher Block Chaining, CBC)的技术。其基本思想是仅随第一个报文发送一个随机值,然后让发送方和接收方使用计算的编码块代替后继的随机数。第一个随机值称为初始向量(Initialization Vector, IV)

### 8.2.2 公开密钥加密
也称为非对称加密。   
![image](https://github.com/user-attachments/assets/a72f52dc-61f5-45cb-866f-8a24cc8f8eaf)    

最出名的非对称算法是RSA算法。RSA的安全性依赖于这样的事实：目前没有已知的算法可以快速进行一个数的因数分解,这种情况下公开值"无法快速分解成素数p和g。如果已知p和g,则给定公开值e就很容易计算出秘密密钥d。另一方面，不确定是否存在因数分解一个数的快速算法，从这种意义上来说，RSA的安全性也不是确保的。    

**会话密钥**   
由于非对称加密很慢，所以经常做法是和对称加密搭配使用。即开始的时候用非对称加密交换对称机密的秘钥，后续就用对称加密。

## 8.3 报文完整性和数字签名
### 8.3.1 密码散列函数
**密码散列函数**（cryptographic hash function）要求具有下列附加的性质：找到任意两个不同的报文咒和y使得H(x)=H(y), 在计算上是不可能的。散列算法有md5(不安全)，SHA-1（推荐）。

### 8.3.2 报文鉴别码(Message Authentication Code, MAC)
Alice生成报文m,用s级联m以生成m+s,并计算散列H(m+s) (例如使用SHA-1)。H(m + s)被称为**报文鉴别码**(Message Authentication Code, MAC)       
![image](https://github.com/user-attachments/assets/d4166324-4602-46e8-bdf7-bfc5df5fa6ad)

### 8.3.3 数字签名
![image](https://github.com/user-attachments/assets/913555af-4211-41d0-b418-240e2228efba)   

![image](https://github.com/user-attachments/assets/8819cf7e-9ce9-477b-92ce-39a4ed82052b)

**公钥认证**
将公钥与特定实体绑定通常是由认证中心（Certification Authority, CA）完成的

## 8.4 端点鉴别
端点鉴别（end-point authentication）就是一个实体经过计算机网络向另一个实体证明其身份的过程：
1. Alice向Bob发送报文“我是Alice”
2. Bob选择一个不重数R, 然后把这个值发送给Alice
3. Alice使用她与Bob共享的对称秘密密钥来加密这个不重数，然后把加密的不重数Ka-b(R)发回给Bob 由于Alice知道秘钥并用它加密一个值，就使得Bob知道收到的报文是由Alice产生的。这个不重数用于确定Alice是活跃的。
4. Bob解密接收到的报文。如果解密得到的不重数等于他发送给Alice的那个不重数，则可鉴别Alice的身份。

![image](https://github.com/user-attachments/assets/f48c8ad3-c931-432c-99df-13c70d93d925)

## 8.5 安全电子邮件
### 8.5.1 安全电子邮件
![image](https://github.com/user-attachments/assets/f7b54663-12f8-4d42-ba87-697ff890d831)

## 8.6 使TCP连接安全：SSL
SSL握手的步骤如下：
1. 客户发送它支持的密码算法的列表，连同一个客户的不重数。
2. 从该列表中，服务器选择一种对称算法（例如AES） 一种公钥算法（例如具有特定密钥长度的RSA）和一种MAC算法。它把它的选择以及证书和一个服务器不重数返回给客户。
3. 客户验证该证书，提取服务器的公钥，生成一个前主密钥（Pe Master Secret, PMS）,用服务器的公钥加密该PMS,并将加密的PMS发送给服务器。
4. 使用相同的密钥导岀函数（就像SSL标准定义的那样），客户和服务器独立地从PMS和不重数中计算出主密钥（Master Secret, MS）。然后该MS被切片以生成两个密码和两个MAC密钥。此外，当选择的对称密码应用于CBC （例如3DES或AES）,则两个初始化向量（Initialization Vector, IV）也从该MS获得，这两个IV分别用于该连接的两端。自此以后，客户和服务器之间发送的所有报文均被加密和鉴别（使用MAC）
5. 客户发送所有握手报文的一个MAC
6. 服务器发送所有握手报文的一个MAC

## 8.7 网络层安全性：IPsec和虚拟专用网
![image](https://github.com/user-attachments/assets/7434f032-7561-4c6e-a6d4-bc62214c3418)   

在IPsec协议族中，主要的是封装安全性载荷（Encapsulation Security Payload, ESP）协议。    

IPsec数据报在网络实体对之间发送，例如两台主机之间、两台路由器之间或一台主机和一台路由器之间。在从源实体向目的实体发送IPsec数据报之前，源和目的实体创建了一个网络层的逻辑连接。这个逻辑连接称为安全关联（Security Association, SA），一个SA是一个单工逻辑连接；   

IPsec主要分组形式是一种用于所谓**隧道模式**（tunnel mode ）

## 8.8 使无线LAN安全
802.11比较弱有已知问题，802.11i是增强的替换版本

## 8.9 运行安全性：防火墙和入侵检测系统
略

## 8.10 小结
在本章中，我们考察了秘密情人Bob和Alice能够用于安全通信的各种机制。我们看到Bob和Alice对下列因素感兴趣：机密性（因此只有他们才能理解传输的报文内容）、端点鉴别（因此他们确信正在与对方交谈）和报文完整性（因此他们确信在传输过程中他们的报文未被篡改）。当然，安全通信的需求并不限于秘密情人。的确，我们在8.5〜8.8节中看到，可以在网络体系结构中的各个层次使用安全性，使之免受采用各种各样攻击手段的坏家伙们的侵扰。   

本章前面部分给出了安全通信所依赖的各种原理。在8.2节中，我们涉及了加密和解密数据的密码技术，包括对称密钥密码和公开密钥密码。作为今天网络中两种重要的密码技术的特定的学习案例，我们考察了DES和RSA。   

在8.3节中，我们研究了提供报文完整性的两种方法：报文鉴别码（MAC）和数字签名。这两种方法有一些共同之处。它们都使用了密码散列函数，这两种技术都使我们能够验证报文的源以及报文自身的完整性。一个重要的差异是MAC不依赖于加密，而数字签名要求公钥基础设施。如我们在8.5~8.8节所见，这两种技术广泛在实际中都得到了广泛应用。此外，数字签名用于生成数字证书，数字证书对于证实公钥的合法性是重要的。在8.4节中，我们考察了端点鉴别并引入了不重数以防御重放攻击。   

在8.5-8.8节中，我们研究了几种在实践中得到广泛使用的安全性网络协议。我们看到了对称密钥密码在PGP SSL IPsec和无线安全性中的核心地位。我们看到了公开密钥密码对PGP和SSL是至关重要的。我们看到PGP使用数字签名而SSL和IPsec使用MAC来保证报文完整性。在目前理解了密码学的基本原理以及学习了这些原理的实际应用方法之后，你现在已经有能力设计你自己的安全网络协议了!    

利用8.2〜8.4节所包含的技术，Bob和Alice就能够安全通信了。（只希望他们是学习了这些材料的网络专业学生，因此能够使他们的约会不会被Trudy发现！）而机密性仅是整个网络安全的一小部分。如我们在8.9节中所学习，现在网络安全的焦点越来越多地关注网络基础设施的安全性，以防止“坏家伙”的潜在猛烈攻击。在本章的后面部分，我们因此学习了防火墙和IDS系统，它们检查进入和离开一个机构网络的分组.

# 多媒体网络
## 9.1 多媒体网络应用
### 9.1.1 视频的性质
视频最为显著的特点或许是它的高比特率 high bitrate）；视频的另一种重要特点是它能被压缩，因而要在视频质量与比特率间进行折中。

### 9.1.2 音频的性质
脉冲编码调制（Pulse Code Modulation, PCM）。语音编码通常采用PCM,采样速率为每秒8000个样本，每个样本用8比特表示，得到64kbps的速率。PCM编码很少在因特网中使用，取而代之的是使用压缩技术来减小流的比特速率：MP3、高级音频编码（Advanced Audio Coding, AAC）   

尽管音频比特率通常比视频的比特率小得多，但用户通常对音频的小失误比视频的小失误更为敏感。

### 9.1.3 多媒体网络应用的类型
1. 流式存储音频和视频
   * **流**。在流式存储视频应用中，客户开始从服务器接收文件几秒之后，通常就开始播放视频。这种技术被称为流（streaming）。
   * **相互作用**。因为媒体是预先录制的，用户可以对多媒体内容进行暂停、重新配置前进、重新配置倒退、快进等操作
   * **连续播放**。为了在客户端播放，必须从服务器中及时接收数据；否则，用户经历视频帧停滞（这时客户等待延迟的帧）或帧跳过（这时客户漏掉延迟的帧）。
2. 会话式IP语音和视频
   * **高度时延敏感**（delay sensitive）
   * **容忍丢包**（loss-tolerant）,即偶尔的丢失只会在音频/视频回放时偶尔出现干扰信号，而且这些丢失经常可以部分或者全部地隐藏
3. 流式实况音频和视频
   * 类似于传统的电台广播和电视
   * 通常是用CDN来实现
   * 尽管定时限制没有会话式语音那么严格，但时延也可能成为问题: 能够容忍的时延最多为10秒
  
## 9.2 流式存储视频
流式视频系统可分为三种类型：UDP 流(UDP streaming)、HTTP 流(HTTP streaming)和适应性 HTTP流(adaptive HTTP streaming)(参见2.6节)。绝大多数今天的系统应用了 HTTP流和适应性HTTP流。
   
### 9.2.1 UDP流
使用UDP流，服务器通过UDP以一种稳定的速率记录下视频块，用与客户的视频消耗速率相匹配的速率传输视频。   
UDP三个重大不足:   
1. 由于服务器和控制之间的可用带宽无法预测并且是变化的，恒定速率UDP流不能够提供连续的播放
2. 它要求如RTSP服务器这样的媒体控制服务器，以对每个进行中的客户会话处理客户到服务器的交互请求和跟踪客户状态（例如在视频中的客户播放点，视频是否被暂停或播放等）。这增加了部署大规模的按需视频系统的总体成本和复杂性。
3. 许多防火墙配置为阻塞UDP流量,防止这些防火墙后面的用户接收UDP视频

### 9.2.2 HTTP流
1. 预取视频：于缓解变化的端到端时延和变化的可用带宽的影响。
2. 客户应用缓存和TCP缓存：当使用HTTP流时，一个满的客户应用缓存间接地对服务器到客户能够发送的视频速率施加了限制。
3. 流式视频的分析：当网络中可用速率小于视频速率时，播放将在连续播放期和停滞播放期之间进行变动；当网络中的可用速率大于视频速率时，在初始缓存时延后，用户将享受连续的播放直到视频结束。
4. 视频的早期中止和重定位：HTTP流系统经常利用HTTP GET请求报文中的HTTP字节范围首部(HTTP byte range header）,该首部指示了客户当前要从所希望的视频中获取的字节范围。   
   
第三种流是经HTTP 的动态适应流(DASH）, DASH使用了该视频的多个版本，每个版本是以不同速率压缩而成的。DASH在2.6.2节中进行了详细讨论。分发存储和实况视频经常使用CDNO CDN在2.6.3节中进行了详细讨论。

## 9.3 IP语音
### 9.3.1 尽力而为服务的限制
接收方必须仔细地判断：①什么时候播放一个块；②如何处理一个丢失块。
1. 丢包: 由于tcp的重传和拥塞算法，使得voip基本基本使用udp, 1~2%的丢包是可以接受的，10~20%无论采取何种措施都无法获得可以接受的声音质量了
2. 端到端时延: VoIP应用程序的接收方通常忽略时延超过特定阈值(例如超过400ms)的任何分组。因此，时延超过该阈值的分组等效于丢弃
3. 分组时延抖动: 如果接收方忽略了时延抖动的存在，一旦该块到达就开始播放，那么在接收方产生的音频质量很容易变得不可理解。幸运的是，时延抖动通常可以通过使用序号(sequence number) ,时间戳(timestamp)和播放时延(playout delay)来消除
